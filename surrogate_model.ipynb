{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoshGrose/Surrogate-Model/blob/main/surrogate_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-JOTUPfj2E9",
        "outputId": "0ebfe05b-d749-4252-e51f-bf4a1007a6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks/\n",
            "This was sent back from the TACC Jupyter Notebook\n"
          ]
        }
      ],
      "source": [
        "#@title Imports and Paths\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "import joblib\n",
        "\n",
        "# implement Neural Network to learn the full dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "#from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from tensorflow.python.keras.models import load_model\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import optimizer_v2 as opt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# connect to drive\n",
        "\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  filepath = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "except:\n",
        "  print(\"Not Connected to Google Colab\")\n",
        "  filepath = '/home1/07329/joshg/surrogate_model'\n",
        "\n",
        "\n",
        "#filepath = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "\n",
        "print(filepath)\n",
        "print('This was sent back from the TACC Jupyter Notebook')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrjXFDqpnvPx",
        "outputId": "16affafc-7ffe-4747-c0e0-12648147d2bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ],
      "source": [
        "#@title Check for GPU\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ39dR0Tn0rs",
        "outputId": "986925b0-ab0f-47a4-bd14-b3af3e3cbc6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "#@title Check for Higher RAM\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "GD5VdLQ_Cl2V"
      },
      "outputs": [],
      "source": [
        "#@title System and Model Parameters\n",
        "# mask information\n",
        "#train_img = 'ibeam'\n",
        "#test_img = 'circle'  #'yinyang' #'circle'  #'square_1mm' # 'leaf'\n",
        "train_img_list = ['ibeam_1_30','smallsquare_1_30','yinyang_1_30',\n",
        "                  'ibeam_2_30','smallsquare_2_30','yinyang_2_30',\n",
        "                  'ibeam_vanish_20','smallsquare_vanish_20','yinyang_vanish_20',\n",
        "                  'ibeam_vanish_40','smallsquare_vanish_40','yinyang_vanish_40',\n",
        "                  'ibeam_grow_20','smallsquare_grow_20','yinyang_grow_20',\n",
        "                  'ibeam_grow_40','smallsquare_grow_40','yinyang_grow_40',] #, 'square_1mm','rectangle'] #, 'square_1mm'] #['ibeam','yinyang','smallsquare'] #,'square_1mm','spiral']\n",
        "\n",
        "mask_list = ['square_opt_1','square_opt_2','square_opt_3','square_opt_4',\n",
        "                    'square_opt_5','square_opt_6','square_opt_7','square_opt_8',\n",
        "                    'square_opt_9','square_opt_10']\n",
        "\n",
        "'''\n",
        "['square_opt_rev_1','square_opt_rev_2','square_opt_rev_3','square_opt_rev_4',\n",
        "                    'square_opt_rev_5','square_opt_rev_6','square_opt_rev_7','square_opt_rev_8',\n",
        "                    'square_opt_rev_9','square_opt_rev_10','square_opt_rev_11','square_opt_rev_12',]\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "pred_img_list = ['square_opt_short']  # square_opt2 is the current full mask optimized result (without property updates)\n",
        "\n",
        "timestep_dict = {\n",
        "    'assassin': 134,\n",
        "    'leaf': 133,\n",
        "    'dragon': 133,\n",
        "    'square_1mm_val': 133,\n",
        "    'circle': 133,\n",
        "    'longhorn': 134,\n",
        "    'spiral': 133,\n",
        "    'assassin_val': 118,\n",
        "    'leaf_val': 117,\n",
        "    'dragon_val': 125,\n",
        "    'square_1mm_val': 133,\n",
        "    'circle_val': 133,\n",
        "    'longhorn_val': 117,\n",
        "    'spiral_val': 119,\n",
        "    'circle_bd3_2':195,\n",
        "    'circle_bd3_6':222\n",
        "}\n",
        "\n",
        "# Major Script Parameters\n",
        "num_timesteps =  131 #timestep_dict[pred_img_list[0]] #assassin_val: 118,  leaf_val: 117,  dragon_val: 125, square_1mm_val/circle_val: 133    #118, plus  # set based on the mask data\n",
        "task = 'train' # 'train', 'pred'\n",
        "dist_exp = 1.21 #1.21 # 1.2 for BIS a,b \n",
        "model_name = 'heat_cool_16_nodes' #(no decay=30 data) #_nozones1_5\n",
        "\n",
        "#checkpoint = ModelCheckpoint(.....) # use this to periodically save weights when training long model in background\n",
        "model_type = 'nn' # 'nn', 'xgb', 'lgbm', 'rf'\n",
        "act_fun = 'relu' # 'relu' for BIS \n",
        "\n",
        "# Neural Network Parameters\n",
        "num_nodes = 16 # 16 for BIS\n",
        "num_hidden_layers = 3 # 3 for BIS\n",
        "\n",
        "# Xgboost parameters \n",
        "xgb_params = {'n_estimators': 600,\n",
        "        'verbose': 0,    \n",
        "        'max_depth': 12,\n",
        "        'learning_rate': 0.02,\n",
        "        'tree_method': \"hist\"}\n",
        "\n",
        "# LightGBM\n",
        "lgbm_params = {'objective': 'regression',\n",
        "              'metric': 'l2',\n",
        "              'is_unballanced': 'true',\n",
        "              'boosting': 'gbdt',\n",
        "              'num_leaves': 280,\n",
        "              'feature_fraction': 0.6,\n",
        "              'baging_fraction': 0.9,\n",
        "              'bagging_freq': 10,\n",
        "              'learning_rate': 0.03,\n",
        "              'verbose': -1,\n",
        "              'num_trees': 400\n",
        "              }\n",
        "\n",
        "# FEATURE TUNING\n",
        "features = ['temp','qgen']\n",
        "num_feat = len(features)\n",
        "num_adjacent = 1  # number of adjacent element features added to feature list\n",
        "udrl = False # for BIS... False\n",
        "single_temp = False # for BIS... False\n",
        "single_qgen = False # for BIS... False\n",
        "single_dens = False # FALSE for BIS\n",
        "single_dens_change = True # NEW\n",
        "single_qgen_dist = True\n",
        "time_subset = True\n",
        "\n",
        "zone_exp = True # for BIS... True\n",
        "circle_zones = True #True for BIS a, False for b\n",
        "incl_time = True # False for BIS\n",
        "qgen_zones = True # True for BIS\n",
        "delay_jump = 0 # for BIS... 0\n",
        "\n",
        "pred_start = 0 # what timestep should the prediction begin?\n",
        "\n",
        "zone_depth = 2 #2 for BIS  # number of adjacent elements included in each zone\n",
        "num_zones = 6 + delay_jump #6 for BIS w/qgen_dist  # number of adjacent zone features added to features list\n",
        "num_mask_train = len(train_img_list)\n",
        "#incl_elems = 1+8*num_adjacent  # currently set for full zones... u,d,r,l would be 8* instead of 4*\n",
        "\n",
        "col_num_train = num_zones+num_feat*(2*num_adjacent+1)**2\n",
        "\n",
        "# timestep/loadstep information\n",
        "num_ls = 10\n",
        "ls_time = .2\n",
        "start_ts = 16  # THIS SHOULD NOT BE HARD CODED.... .2s/beginning of real simulation\n",
        "sinter_time = .2\n",
        "train_ts = 133 # 133 here works with \"num_timesteps = 131\"\n",
        "\n",
        "# initial temperature to initialize training data\n",
        "temp_init = 22\n",
        "dens_init = 2600\n",
        "\n",
        "# mesh parameters\n",
        "mesh_x = 60\n",
        "mesh_y = 118\n",
        "\n",
        "# aditional parameters\n",
        "num_time = 180 # 240 for grayscale #180 for non val   # (It's used somewhere...)\n",
        "x_min = .00125\n",
        "x_max = .00275\n",
        "y_min = .00150\n",
        "y_max = .00450\n",
        "z_min = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "cellView": "form",
        "id": "OW-nHUS1j2eO"
      },
      "outputs": [],
      "source": [
        "#@title import_data\n",
        "def import_data(filepath, name, sep='       |      |     |    |   |  | '):\n",
        "      \"\"\"Returns imported data\"\"\"\n",
        "      return(pd.read_csv(filepath + name, sep, header=None).to_numpy(copy=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "T-M_bafpkCfb"
      },
      "outputs": [],
      "source": [
        "#@title getLastVal\n",
        "def getLastVal(val_mat):\n",
        "    '''Get last nonzero value for filtering'''\n",
        "    binary_array = (val_mat[0,0,:]!=0.0) #.argmax()\n",
        "    last_val = np.argmax(binary_array == False)\n",
        "    return last_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "cellView": "form",
        "id": "vSySBKLIkDn5"
      },
      "outputs": [],
      "source": [
        "#@title filterStart\n",
        "def filterStart(val_mat,start_ts,time=False):\n",
        "    '''filter out initial bad data'''\n",
        "    if time == False:\n",
        "        val_mat_filt = val_mat[:,:,start_ts:]\n",
        "    else:\n",
        "        val_mat_filt = val_mat[start_ts:]\n",
        "    \n",
        "    return val_mat_filt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "_km1LS4KkJ_c"
      },
      "outputs": [],
      "source": [
        "#@title filterEnd\n",
        "def filterEnd(val_mat, last_val, time=False):\n",
        "    '''filter out initial bad data'''\n",
        "    if time == False:\n",
        "        val_mat_filt = val_mat[:,:,:last_val]\n",
        "    else:\n",
        "        val_mat_filt = val_mat[:last_val]\n",
        "    \n",
        "    return val_mat_filt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "cellView": "form",
        "id": "YdHQQFEhVnCE"
      },
      "outputs": [],
      "source": [
        "#@title setTimeZero\n",
        "def setTimeZero(val_array, initial_val=22, param='temp'):\n",
        "    '''Insert initial condition to matrices'''\n",
        "\n",
        "    if param == 'temp':\n",
        "        val_array_init =  np.insert(val_array,0,initial_val,2)\n",
        "    elif param == 'change':\n",
        "        val_array_init =  np.insert(val_array,0,0,2)\n",
        "    else:\n",
        "        val_array_init =  np.insert(val_array,0,val_array[:,:,0],2)\n",
        "\n",
        "    return val_array_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "cellView": "form",
        "id": "SAz3Gt9AVuCs"
      },
      "outputs": [],
      "source": [
        "#@title setTempMin\n",
        "def setTempMin(temp_array):\n",
        "    temp_array[temp_array<22] = 22\n",
        "    return temp_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "cellView": "form",
        "id": "jo8HYkMakNwZ"
      },
      "outputs": [],
      "source": [
        "#@title createTemperatureMatrix\n",
        "# function library for bed-scale data processing\n",
        "def createTemperatureMatrix(filepath, img_string, num_ls = 9, ls_time = .2, start_ts = 16, mesh_x = 60,\n",
        "                mesh_y = 118, num_time = 180, x_min = .00125, x_max = .00275,\n",
        "                y_min = .00150, y_max = .00450, z_min = 0):\n",
        "\n",
        "    # Timeseries Data\n",
        "    timeseries_name = 'timeseries_' + img_string + '.txt'\n",
        "\n",
        "    # node and element data\n",
        "    nodenums_name = 'node_numbers.txt'\n",
        "    node_list_name = 'node_list.txt'\n",
        "    elem_coords_name = 'element_coordinates.txt'\n",
        "\n",
        "    # element location data for qgen and dens\n",
        "    centx_name = 'centX_filt.txt'\n",
        "    centy_name = 'centY_filt.txt'\n",
        "\n",
        "    # import key variables from text files\n",
        "    nodenums_array_unfilt = import_data(filepath, nodenums_name)\n",
        "    nodenums_array = nodenums_array_unfilt[:,:-1]\n",
        "\n",
        "    elem_loc_array  = import_data(filepath, elem_coords_name)\n",
        "    full_timeseries  = import_data(filepath, timeseries_name)\n",
        "\n",
        "    # split full timeseries into times and temps\n",
        "    temp_timeseries = full_timeseries[:,1:]\n",
        "    time_array_unfilt = full_timeseries[:,0]\n",
        "    time_array = time_array_unfilt[time_array_unfilt != 0]\n",
        "\n",
        "    #print(temp_timeseries.shape)\n",
        "    # boundary conditions to filter elements outside of the main section\n",
        "    a = elem_loc_array[0, :] > x_min\n",
        "    b = elem_loc_array[0, :] < x_max\n",
        "    c = elem_loc_array[1, :] > y_min\n",
        "    d = elem_loc_array[1, :] < y_max\n",
        "    e = elem_loc_array[2, :] > z_min\n",
        "\n",
        "    # filter for elements within \"main\" copper\n",
        "    elem_nodes = []\n",
        "    elem_coords = []\n",
        "\n",
        "    for i in range(0, nodenums_array.shape[1]):\n",
        "        if a[i] and b[i] and c[i] and d[i] and e[i]:\n",
        "            #elem_nodes.append(list(nodenums_array[:, i]))\n",
        "            elem_coords.append(list(elem_loc_array[:, i]))\n",
        "            elem_nodes.append(list(nodenums_array[:, i]))\n",
        "\n",
        "    #PLEASE RENAME THESE\n",
        "    elem_nodes = np.array(elem_nodes)\n",
        "    elem_coords = np.array(elem_coords)\n",
        "    xy = elem_coords[:, :2]\n",
        "\n",
        "    # combine array of element nodes with array of x,y element data\n",
        "    elem_array = np.vstack((xy.transpose(), elem_nodes.transpose())).transpose()\n",
        "\n",
        "    # convert to list for sorting\n",
        "    elem_list = list(elem_array)\n",
        "    elem_sorted = np.array(sorted(elem_list, key=lambda k: [k[1], -k[0]])).transpose()\n",
        "    #print(elem_sorted)\n",
        "\n",
        "    # split elem sorted into two seperate numpy arrays\n",
        "    num_dim = 2  # only x,y coordinates need to be sorted\n",
        "    xy_sorted = elem_sorted[:num_dim, :]\n",
        "    elem_nodes_sorted = elem_sorted[num_dim:, :]\n",
        "\n",
        "    x_ordered = np.reshape(xy_sorted[0], (mesh_x, mesh_y), order='C')\n",
        "    y_ordered = np.reshape(xy_sorted[1], (mesh_x, mesh_y), order='C')\n",
        "\n",
        "    # loop to build ordered element nodes list\n",
        "    num_nodes = len(elem_nodes_sorted[:,0])\n",
        "    elem_nodes_mat = np.zeros((mesh_x, mesh_y, num_nodes))  # 20 for 20 nodes\n",
        "    temp_mat = np.zeros((mesh_x, mesh_y,num_time))\n",
        "    counter = 0\n",
        "\n",
        "    temp_list = []\n",
        "\n",
        "    for col in range(0, mesh_y):\n",
        "        for row in range(0, mesh_x):\n",
        "            node_set = elem_nodes_sorted[:, counter]\n",
        "            #print(node_set)\n",
        "\n",
        "            elem_nodes_mat[row, col, :] = node_set\n",
        "            temp_array = np.zeros((num_time, num_nodes))\n",
        "\n",
        "            # timeseries data orginization\n",
        "            for node_num in range(0, num_nodes):\n",
        "                # get absolute node\n",
        "                node = node_set[node_num]\n",
        "                div = len(np.nonzero(node_set)[0])\n",
        "                if node != 0.0:\n",
        "                    temp_array[:, [node_num]] = temp_timeseries[:, [int(node)-1]]\n",
        "\n",
        "            # for every timestep, sum temp values for all nodes in element\n",
        "            temp_array_avg = np.sum(temp_array, axis=1)/div  #/num_nodes\n",
        "            temp_list.append(temp_array)\n",
        "\n",
        "            temp_mat[row, col, :] = temp_array_avg\n",
        "\n",
        "            counter=counter+1\n",
        "\n",
        "    # TIMESERIES DONE\n",
        "\n",
        "    return temp_mat, time_array, start_ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "OMqQqQjRkDxy"
      },
      "outputs": [],
      "source": [
        "#@title createFeatureMatrix\n",
        "def createFeatureMatrix(filepath, filename, time_array, num_ls = 9, ls_time = .2, start_ts = 16, mesh_x = 60,\n",
        "                mesh_y = 118, num_time = 180, x_min = .00125, x_max = .00275,\n",
        "                y_min = .00150, y_max = .00450, z_min = 0):\n",
        "\n",
        "    # element location data for qgen and dens\n",
        "    centx_name = 'centX_filt.txt'\n",
        "    centy_name = 'centY_filt.txt'\n",
        "\n",
        "\n",
        "    # Density/Qgen or any other imported feature\n",
        "    feature_array  = import_data(filepath, filename, sep=',')\n",
        "    centx_array  = import_data(filepath, centx_name, sep='/n').transpose()\n",
        "    centy_array  = import_data(filepath, centy_name, sep='/n').transpose()\n",
        "\n",
        "    elem_array = np.vstack((centx_array, centy_array, feature_array)).transpose()\n",
        "\n",
        "    # convert to list for sorting\n",
        "    elem_list = list(elem_array)\n",
        "    elem_sorted = np.array(sorted(elem_list, key=lambda k: [k[1], -k[0]])).transpose()\n",
        "\n",
        "    # split elem sorted into two seperate numpy arrays\n",
        "    num_dim = 2  # only x,y coordinates need to be sorted\n",
        "    xy_sorted = elem_sorted[:num_dim, :]\n",
        "    feature_sorted = elem_sorted[num_dim: num_dim + num_ls, :]\n",
        "\n",
        "    # structure the feature matrices\n",
        "    feature_mat = np.zeros((mesh_x, mesh_y, num_time))\n",
        "    #print(feature_mat.shape)\n",
        "\n",
        "    counter = 0\n",
        "    #print(num_ls)\n",
        "    for col in range(0, mesh_y):\n",
        "        for row in range(0, mesh_x):\n",
        "\n",
        "            time_ind_old = 0\n",
        "            # added code to extend density and qgen over timeseries instead of just loadstep\n",
        "            # this code ignores the first few timesteps where nothing happens\n",
        "            for ls in range(1,num_ls+1):\n",
        "\n",
        "                time_end = round(ls*ls_time,4)\n",
        "                time_ind = np.where(time_array == time_end)\n",
        "                #print(time_end)\n",
        "                #print(time_end + 1.0)\n",
        "                time_ind = time_ind[0][0]  # doesnt work for ts = 240 and ls = 9\n",
        "\n",
        "                feature_mat[row, col, time_ind_old:time_ind] = feature_sorted[ls-1, counter]\n",
        "                time_ind_old = time_ind\n",
        "\n",
        "            counter=counter+1\n",
        "\n",
        "\n",
        "    return feature_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "oquoUFXQddJu"
      },
      "outputs": [],
      "source": [
        "#@title createMaskSegment\n",
        "def createMaskSegment(filepath, filename, time_array, num_ls = 9, ls_time = .2, start_ts = 16, mesh_x = 60,\n",
        "                mesh_y = 118, start_ls = 0, ls_duration = 1, x_min = .00125, x_max = .00275,\n",
        "                y_min = .00150, y_max = .00450, z_min = 0):\n",
        "\n",
        "    # ls_duration -> number of loadsteps that this mask should remain on filepath, qgen_name, time_array, start_ls = start_ls, ls_duration = ls_duration, num_ls = num_ls\n",
        "\n",
        "    # element location data for qgen and dens\n",
        "    centx_name = 'centX_filt.txt'\n",
        "    centy_name = 'centY_filt.txt'\n",
        "\n",
        "\n",
        "    # Density/Qgen or any other imported feature\n",
        "    feature_array  = import_data(filepath, filename, sep=',')\n",
        "    centx_array  = import_data(filepath, centx_name, sep='/n').transpose()\n",
        "    centy_array  = import_data(filepath, centy_name, sep='/n').transpose()\n",
        "\n",
        "    elem_array = np.vstack((centx_array, centy_array, feature_array)).transpose()\n",
        "\n",
        "    # convert to list for sorting\n",
        "    elem_list = list(elem_array)\n",
        "    elem_sorted = np.array(sorted(elem_list, key=lambda k: [k[1], -k[0]])).transpose()\n",
        "\n",
        "    # split elem sorted into two seperate numpy arrays\n",
        "    num_dim = 2  # only x,y coordinates need to be sorted\n",
        "    xy_sorted = elem_sorted[:num_dim, :]\n",
        "    feature_sorted = elem_sorted[num_dim: num_dim + num_ls, :]\n",
        "\n",
        "    # initial and final time indices\n",
        "    \n",
        "    if start_ls == 0:\n",
        "        time_start = 0.2000\n",
        "        time_start_ind = 0\n",
        "    else:\n",
        "        time_start = round((start_ls+1)*ls_time,4)\n",
        "        #print(start_ls)\n",
        "        #print(time_start)\n",
        "        time_start_loc = np.where(time_array == time_start)\n",
        "        time_start_ind = time_start_loc[0][0]\n",
        "\n",
        "    time_end = round(time_start + ls_duration*ls_time,4)\n",
        "    time_end_loc = np.where(time_array == time_end)\n",
        "    time_end_ind = time_end_loc[0][0]  # doesnt work for ts = 240 and ls = 9\n",
        "    \n",
        "    # structure the feature matrices\n",
        "    #print('min time')\n",
        "    #print(np.amin(time_array[:]))\n",
        "  \n",
        "    #print(time_end_ind - time_start_ind)\n",
        "    feature_mat = np.zeros((mesh_x, mesh_y, time_end_ind - time_start_ind))\n",
        "\n",
        "    counter = 0\n",
        "    #print(num_ls)\n",
        "    for col in range(0, mesh_y):\n",
        "        for row in range(0, mesh_x):\n",
        "                        \n",
        "            feature_mat[row, col, :] = feature_sorted[0, counter] # any index should work for this, since the qgen file is uniform\n",
        "            counter=counter+1\n",
        "\n",
        "    return feature_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "cellView": "form",
        "id": "qj5kvLKfUseD"
      },
      "outputs": [],
      "source": [
        "#@title getAdjacentFeatures\n",
        "def getAdjacentFeatures(temp_mat, last_val, mesh_x=60, mesh_y=118, num_adjacent = 1, udrl = False):\n",
        "\n",
        "    # get size parameters needed to formulate training data\n",
        "    adj = num_adjacent\n",
        "    num_time_filt = last_val\n",
        "    num_elem = mesh_x*mesh_y\n",
        "    num_points = num_time_filt*num_elem - num_elem\n",
        "\n",
        "    # get expanded matrix for easier looping\n",
        "    temp_mat_exp = expandTempMeshTrain(temp_mat, num_adjacent)\n",
        "    shape = temp_mat_exp.shape\n",
        "\n",
        "    # get the number of features\n",
        "    u_bound, l_bound = 0, 0    # this being 0 might account for the center element data (no need for the +1)\n",
        "    for adj in range(1, num_adjacent+1):\n",
        "        u_bound += adj*8\n",
        "    num_cols = u_bound + 1\n",
        "\n",
        "    # set the size of the feature matrix\n",
        "    features_mat = np.zeros((num_points, num_cols))  # can also be num_adjacent*8 for the number of surrounding points\n",
        "\n",
        "    counter = 0\n",
        "    # no need to loop through, just reshape the matrix and make sure the intended column vectors are correct\n",
        "    for col in range(num_adjacent, mesh_y+adj):\n",
        "        for row in range(num_adjacent, mesh_x+adj): # NEED TO ACCOUNT FOR ADJ=0\n",
        "\n",
        "            feature_columns = temp_mat_exp[row-adj:row+adj+1,col-adj:col+adj+1,:-1].reshape(num_cols,shape[2]-1).T #.reshape(shape[2]-1,num_cols)    #order='C', exclude final column\n",
        "            features_mat[counter:num_points:num_elem, l_bound:num_cols] = feature_columns\n",
        "            counter+=1\n",
        "\n",
        "    # only get features corresponding to up, down, right, left elements\n",
        "    if udrl and num_adjacent == 1:\n",
        "        features_mat = features_mat[:, 1::2]\n",
        "\n",
        "    return features_mat, temp_mat_exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "cellView": "form",
        "id": "m3aizV6vyDaz"
      },
      "outputs": [],
      "source": [
        "#@title getAdjacentFeaturesPredict\n",
        "def getAdjacentFeaturesPredict(temp_mat, last_val, mesh_x=60, mesh_y=118, num_adjacent = 1, udrl = False):\n",
        "\n",
        "    # get size parameters needed to formulate training data\n",
        "    adj = num_adjacent\n",
        "    num_time_filt = last_val\n",
        "    num_elem = mesh_x*mesh_y\n",
        "\n",
        "    # get expanded matrix for easier looping\n",
        "    temp_mat_exp = expandTempMeshPredict(temp_mat, num_adjacent)\n",
        "    shape = temp_mat_exp.shape\n",
        "\n",
        "    # get the number of features\n",
        "    u_bound, l_bound = 0, 0    # this being 0 might account for the center element data (no need for the +1)\n",
        "    for adj in range(1, num_adjacent+1):\n",
        "        u_bound += adj*8\n",
        "    num_cols = u_bound + 1\n",
        "\n",
        "    # set the size of the feature matrix\n",
        "    features_mat = np.zeros((num_elem, num_cols))  # can also be num_adjacent*8 for the number of surrounding points\n",
        "\n",
        "    counter = 0\n",
        "    # no need to loop through, just reshape the matrix and make sure the intended column vectors are correct\n",
        "    for col in range(num_adjacent, mesh_y+adj):\n",
        "        for row in range(num_adjacent, mesh_x+adj):\n",
        "\n",
        "            #print(temp_mat_exp[row-adj:row+adj+1,col-adj:col+adj+1])\n",
        "            feature_columns = temp_mat_exp[row-adj:row+adj+1,col-adj:col+adj+1].reshape(1,num_cols)    #order='C', exclude final column\n",
        "            features_mat[counter, l_bound:num_cols] = feature_columns\n",
        "\n",
        "            counter+=1\n",
        "\n",
        "    if udrl and num_adjacent == 1:\n",
        "        features_mat = features_mat[:, 1::2]\n",
        "\n",
        "    return features_mat, temp_mat_exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "cellView": "form",
        "id": "JShkacJVI2et"
      },
      "outputs": [],
      "source": [
        "#@title getAdjacentSingle\n",
        "def getAdjacentSingle(temp_mat_train, last_val, mesh_x=60, mesh_y=118):\n",
        "\n",
        "    #num_feats = num_feat*incl_elems  # +1 for density change\n",
        "    num_time_filt = last_val\n",
        "    num_elem = mesh_x*mesh_y\n",
        "\n",
        "    num_points = num_time_filt*num_elem - num_elem\n",
        "\n",
        "    label_data = np.zeros((num_points, 1)) # SINGLE LABEL\n",
        "    counter = 0\n",
        "    for col in range(0, mesh_y):\n",
        "        for row in range(0, mesh_x):\n",
        "            label_data[counter:num_points:num_elem, 0] = temp_mat_train[row,col,:-1]\n",
        "            counter+=1\n",
        "\n",
        "    return label_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "cellView": "form",
        "id": "OxjDTioGI2sf"
      },
      "outputs": [],
      "source": [
        "#@title getAdjacentSinglePredict\n",
        "def getAdjacentSinglePredict(feat_mat, last_val, mesh_x=60, mesh_y=118):\n",
        "\n",
        "    num_elem = mesh_x*mesh_y\n",
        "    label_data = np.zeros((num_elem, 1)) # SINGLE LABEL\n",
        "\n",
        "    counter = 0\n",
        "    for col in range(0, mesh_y):\n",
        "        for row in range(0, mesh_x):\n",
        "            label_data[counter, 0] = feat_mat[row,col]\n",
        "            counter+=1\n",
        "\n",
        "    return label_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "cellView": "form",
        "id": "vU9q0RJBccgh"
      },
      "outputs": [],
      "source": [
        "#@title get_time_feat_predict\n",
        "def get_time_feat_predict(time_delta, mesh_x, mesh_y):\n",
        "    \n",
        "    num_elem = mesh_x*mesh_y\n",
        "    time_data = np.zeros((num_elem, 1)) + time_delta # SINGLE LABEL\n",
        "\n",
        "    return time_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "cellView": "form",
        "id": "rYMXj-fp4qGp"
      },
      "outputs": [],
      "source": [
        "#@title get_time_feat\n",
        "def get_time_feat(time_diff_array, mesh_x, mesh_y, last_val):\n",
        "    \n",
        "    #num_feats = num_feat*incl_elems  # +1 for density change\n",
        "    num_time_filt = last_val\n",
        "    num_elem = mesh_x*mesh_y\n",
        "\n",
        "    num_points = num_time_filt*num_elem - num_elem\n",
        "\n",
        "    time_data = np.zeros((num_points, 1)) # SINGLE LABEL\n",
        "    counter = 0\n",
        "    for col in range(0, mesh_y):\n",
        "        for row in range(0, mesh_x):\n",
        "            time_data[counter:num_points:num_elem, 0] = time_diff_array\n",
        "            counter+=1\n",
        "\n",
        "    return time_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "cellView": "form",
        "id": "K2PucxVNV_0_"
      },
      "outputs": [],
      "source": [
        "#@title expandTempMeshPredict\n",
        "def expandTempMeshPredict(temp_mat, num_included_elems):\n",
        "    '''\n",
        "    This works for multiple timesteps all at once\n",
        "    '''\n",
        "    # temp_map is a timestep slice of the full temp_mat (ex: all temperatures at a specified timestep)\n",
        "\n",
        "    n = num_included_elems\n",
        "    # expand left, down, up, right (CCW)\n",
        "\n",
        "    # add left columns\n",
        "    temp_shape = temp_mat.shape\n",
        "    #print(temp_shape)\n",
        "\n",
        "    left_temps = np.reshape(temp_mat[:,0],(-1,1)) #np.reshape(temp_mat[:,0,:], (temp_shape[0],-1,temp_shape[2])) #y=np.reshape(y, (-1,1))\n",
        "    left_temps_opp = np.tile(left_temps, (1,n)) #temp_mat[:,1:n+1]\n",
        "    left_array = left_temps_opp #np.flip(left_temps - abs(left_temps - left_temps_opp), axis=1)\n",
        "    temp_mat = np.hstack((left_array,temp_mat))\n",
        "    temp_shape = temp_mat.shape\n",
        "\n",
        "    # add bottom rows\n",
        "    #print(temp_mat[-1,:,:].shape)\n",
        "    bottom_temps = np.reshape(temp_mat[-1,:],(1,-1)) #np.reshape(temp_mat[-1,:,:], (-1,temp_shape[1],temp_shape[2]))\n",
        "    bottom_temps_opp = np.tile(bottom_temps, (n,1)) #temp_mat[-1*n-1:-1,:]\n",
        "    bottom_array = bottom_temps_opp #np.flip(bottom_temps - abs(bottom_temps - bottom_temps_opp), axis=0)\n",
        "    temp_mat = np.vstack((temp_mat, bottom_array))\n",
        "    temp_shape = temp_mat.shape\n",
        "\n",
        "    # add right columns\n",
        "    right_temps = np.reshape(temp_mat[:,-1],(-1,1)) #np.reshape(temp_mat[:,-1,:], (temp_shape[0],-1,temp_shape[2]))\n",
        "    right_temps_opp = np.tile(right_temps, (1,n)) #temp_mat[:,-1*n-1:-1]\n",
        "    #print(right_temps.shape)\n",
        "    right_array = right_temps_opp  #np.flip(right_temps - abs(right_temps - right_temps_opp), axis=1)\n",
        "    temp_mat = np.hstack((temp_mat, right_array))\n",
        "    temp_shape = temp_mat.shape\n",
        "\n",
        "    # add top rows\n",
        "    top_temps = np.reshape(temp_mat[0,:],(1,-1)) #np.reshape(temp_mat[0,:,:], (-1,temp_shape[1],temp_shape[2]))\n",
        "    top_temps_opp = np.tile(top_temps, (n,1)) #temp_mat[1:n+1,:]\n",
        "    #print(top_temps.shape)\n",
        "    top_array = top_temps_opp #np.flip(top_temps - abs(top_temps - top_temps_opp), axis=0)\n",
        "    temp_mat = np.vstack((top_array, temp_mat))\n",
        "\n",
        "    #print(temp_mat.shape)\n",
        "\n",
        "    return temp_mat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "cellView": "form",
        "id": "890HDzII1ecL"
      },
      "outputs": [],
      "source": [
        "#@title expandTempMeshTrain\n",
        "def expandTempMeshTrain(temp_mat, num_included_elems):\n",
        "    '''\n",
        "    This works for multiple timesteps all at once\n",
        "    '''\n",
        "    # temp_map is a timestep slice of the full temp_mat (ex: all temperatures at a specified timestep)\n",
        "\n",
        "    n = num_included_elems\n",
        "    # expand left, down, up, right (CCW)\n",
        "\n",
        "    # add left columns\n",
        "    temp_shape = temp_mat.shape\n",
        "    #print(temp_shape)\n",
        "\n",
        "    left_temps = np.reshape(temp_mat[:,0,:], (temp_shape[0],-1,temp_shape[2]))\n",
        "    #print(left_temps.shape)\n",
        "    ####left_temps = temp_mat[:,0, :]\n",
        "    print(left_temps.shape)\n",
        "    left_array = np.tile(left_temps, (1,n,1))  #np.flip(temp_mat[:,1:n+1, :], axis = 1) #np.flip(left_temps - abs(left_temps - temp_mat[:,1:n+1, :]), axis=1)\n",
        "    temp_mat = np.hstack((left_array,temp_mat))\n",
        "    temp_shape = temp_mat.shape\n",
        "\n",
        "    # add bottom rows\n",
        "    #print(temp_mat[-1,:,:].shape)\n",
        "    bottom_temps = np.reshape(temp_mat[-1,:,:], (-1,temp_shape[1],temp_shape[2]))\n",
        "    #print(bottom_temps.shape)\n",
        "    #bottom_temps = temp_mat[-1,:, :]\n",
        "    bottom_array = np.tile(bottom_temps, (n,1,1)) #np.flip(bottom_temps - abs(bottom_temps - temp_mat[-1*n-1:-1,:,:]), axis=0)\n",
        "    temp_mat = np.vstack((temp_mat, bottom_array))\n",
        "    temp_shape = temp_mat.shape\n",
        "\n",
        "    # add right columns\n",
        "    right_temps = np.reshape(temp_mat[:,-1,:], (temp_shape[0],-1,temp_shape[2]))\n",
        "    #print(right_temps.shape)\n",
        "    ####right_temps = temp_mat[:,-1, :]\n",
        "    right_array = np.tile(right_temps, (1,n,1)) #np.flip(right_temps - abs(right_temps - temp_mat[:,-1*n-1:-1,:]), axis=1)\n",
        "    temp_mat = np.hstack((temp_mat, right_array))\n",
        "    temp_shape = temp_mat.shape\n",
        "\n",
        "    # add top rows\n",
        "    top_temps = np.reshape(temp_mat[0,:,:], (-1,temp_shape[1],temp_shape[2]))\n",
        "    #print(top_temps.shape)\n",
        "    ####top_temps = temp_mat[:,0, :]\n",
        "    top_array = np.tile(top_temps, (n,1,1)) #np.flip(top_temps - abs(top_temps - temp_mat[1:n+1,:,:]), axis=0)\n",
        "    temp_mat = np.vstack((top_array, temp_mat))\n",
        "    temp_shape = temp_mat.shape\n",
        "\n",
        "    return temp_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "cellView": "form",
        "id": "-IUHiMrGCFPd"
      },
      "outputs": [],
      "source": [
        "#@title getFeatureZones\n",
        "def getFeatureZones(temp_map, qgen_mat, last_val, mesh_x=60, mesh_y=118, num_zones = 3, zone_depth = 3, num_feat = 3, num_adjacent = 1):\n",
        "\n",
        "\n",
        "    num_time_filt = last_val\n",
        "    num_elem = mesh_x*mesh_y\n",
        "    num_points = num_time_filt*num_elem - num_elem\n",
        "\n",
        "    temp_mat_exp = expandTempMeshTrain(temp_map, num_zones)\n",
        "\n",
        "    features_mat = np.zeros((num_points, num_zones))  # can also be num_adjacent*8 for the number of surrounding points\n",
        "    counter = 0\n",
        "    for col_num in range(num_zones, mesh_y+num_zones):\n",
        "        for row_num in range(num_zones, mesh_x+num_zones):\n",
        "\n",
        "            row = row_num + num_zones\n",
        "            col = 1\n",
        "\n",
        "            features_mat[counter:num_points:num_elem, :] = temp_mat_exp[row,col,:-1]\n",
        "            features_mat[counter:num_points:num_elem, :] = temp_mat_exp[row,col,:-1]\n",
        "            features_mat[counter:num_points:num_elem, :] = temp_mat_exp[row,col,:-1]\n",
        "            features_mat[counter:num_points:num_elem, :] = temp_mat_exp[row,col,:-1]\n",
        "            training_data[counter:num_points:num_elem, col_adj] = temp_mat_train[row+col_adj,col,:-1]\n",
        "\n",
        "\n",
        "    return zone_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "cellView": "form",
        "id": "N9NfuKtMgnf4"
      },
      "outputs": [],
      "source": [
        "#@title getFeaturesFromMask\n",
        "# below code nees to be run for all input training masks\n",
        "# make sure all TRAINING matrices are the same size...\n",
        "\n",
        "def getFeaturesFromMask(filepath, train_img, num_time, num_ls):\n",
        "\n",
        "    dens_name = 'density_filt_'  + train_img + '.txt'\n",
        "    qgen_name = 'qgen_norm_filt_'  + train_img + '.txt'\n",
        "    temp_mat, time_array, start_ts = createTemperatureMatrix(filepath, train_img, num_time = num_time)\n",
        "    dens_mat = createFeatureMatrix(filepath, dens_name, time_array, num_time = num_time, num_ls = num_ls) # currently not running for ts=240, ls=9\n",
        "    qgen_mat = createFeatureMatrix(filepath, qgen_name, time_array, num_time = num_time, num_ls = num_ls)\n",
        "    #print(dens_mat.shape)\n",
        "    temp_mat = filterStart(temp_mat, start_ts)\n",
        "    last_val = getLastVal(temp_mat)\n",
        "    temp_mat = filterEnd(temp_mat, last_val)\n",
        "    #print(last_val)\n",
        "    dens_mat = filterEnd(dens_mat, last_val)\n",
        "    qgen_mat = filterEnd(qgen_mat, last_val)\n",
        "    #print(dens_mat.shape)\n",
        "\n",
        "    temp_mat = setTimeZero(temp_mat, initial_val=temp_init, param='temp')\n",
        "    #print(dens_mat.shape)\n",
        "    dens_mat = setTimeZero(dens_mat, param='dens')\n",
        "    qgen_mat = setTimeZero(qgen_mat, param='qgen')\n",
        "\n",
        "    # get density change as a feature\n",
        "    dens_change_mat = dens_mat[:, :, 1:] - dens_mat[:, :, :-1]\n",
        "    dens_change_mat = setTimeZero(dens_change_mat, param='change') # set time 0 for density CHANGE\n",
        "\n",
        "    # adjust last val for t0 values\n",
        "    last_val+=1\n",
        "\n",
        "    # set minimum temperature to 0\n",
        "    temp_mat = setTempMin(temp_mat)\n",
        "\n",
        "    # filter and append to time array (as was done above for the other arrays)\n",
        "\n",
        "    time_array = filterStart(time_array, start_ts-1, time = True)\n",
        "    time_array = filterEnd(time_array, last_val, time = True)\n",
        "\n",
        "    time_diff_array = time_array[1:] - time_array[:-1]\n",
        "    #time_diff_array = time_array\n",
        "\n",
        "    return temp_mat, dens_mat, dens_change_mat, qgen_mat, last_val, time_diff_array, time_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "cellView": "form",
        "id": "1kCNFZdvtBPQ"
      },
      "outputs": [],
      "source": [
        "#@title getQgenFromMask\n",
        "# below code nees to be run for all input training masks\n",
        "# make sure all TRAINING matrices are the same size...\n",
        "\n",
        "def getQgenFromMask(filepath, mask_img, num_time, num_ls, time_array,  start_ls = 0, ls_duration = 1):\n",
        "\n",
        "    qgen_name = 'qgen_norm_filt_'  + mask_img + '.txt'\n",
        "    qgen_mat = createMaskSegment(filepath, qgen_name, time_array, start_ls = start_ls, ls_duration = ls_duration, num_ls = num_ls)\n",
        "    qgen_mat = filterEnd(qgen_mat, last_val)\n",
        "    qgen_mat = setTimeZero(qgen_mat, param='qgen')\n",
        "\n",
        "    return qgen_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "cellView": "form",
        "id": "WcVx4cTXndvj"
      },
      "outputs": [],
      "source": [
        "#@title getTemperatureLabels\n",
        "def getTemperatureLabels(temp_mat_train, last_val, mesh_x=60, mesh_y=118,):\n",
        "\n",
        "    #num_feats = num_feat*incl_elems  # +1 for density change\n",
        "    num_time_filt = last_val\n",
        "    num_elem = mesh_x*mesh_y\n",
        "\n",
        "    num_points = num_time_filt*num_elem - num_elem\n",
        "\n",
        "    label_data = np.zeros((num_points, 1)) # SINGLE LABEL\n",
        "    counter = 0\n",
        "    for col in range(0, mesh_y):\n",
        "        for row in range(0, mesh_x):\n",
        "            label_data[counter:num_points:num_elem, 0] = temp_mat_train[row,col,1:]\n",
        "            counter+=1\n",
        "\n",
        "    return label_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "cellView": "form",
        "id": "ec3ZGrH4tHv4"
      },
      "outputs": [],
      "source": [
        "#@title getQgenZones\n",
        "def getQgenZones(qgen_mat, mesh_x=60, mesh_y=118, num_zones = 3, zone_depth = 3, zone_jump = 1, zone_increase = 2, delay_jump = 0, circle_zones = False, zone_exp = False):\n",
        "    '''\n",
        "    Create mesh shaped data structure for each of the surrounding mesh zones\n",
        "    timestep -1 of qgen_mat is being used here since all timesteps are the same\n",
        "    this will eventually be replaced with whatever mask is being used\n",
        "\n",
        "    Can certainly parallelize this...\n",
        "\n",
        "    zone_depth: size of qgen zones... if zone_exp, size of starting qgen zone\n",
        "    zone_jump: every [zone_jump] zones, the zone_depth increases by zone_increase\n",
        "      \n",
        "    '''\n",
        "\n",
        "    toggle = 'off' #'mult' #'mult', 'custom', 'off'\n",
        "    circzone_shift = .5 # .5 for BIS\n",
        "\n",
        "    arm_len_list = [2, 4, 6, 8, 10, 14, 20, 24, 30, 36, 42, 48]  # only if toggle = 'custom'\n",
        "\n",
        "    num_elem = mesh_x*mesh_y\n",
        "    counter = 0\n",
        "    box_half_len = num_zones*zone_depth\n",
        "    full_zone_depth = zone_depth  # starting length of first zone (2, meaning the zone will be 5x5)\n",
        "\n",
        "    zone_list = []\n",
        "    #zone_increase = 1\n",
        "\n",
        "    for zone_num in range(1, num_zones+1):\n",
        "        #####print('Arm Len')\n",
        "        #print(zone_depth)\n",
        "        #print(full_zone_depth)\n",
        "\n",
        "        if toggle == 'mult':\n",
        "            arm_len = zone_num*zone_depth # this is the old way that generated the BIS model\n",
        "\n",
        "        elif toggle == 'custom':\n",
        "            arm_len = arm_len_list[zone_num-1]\n",
        "\n",
        "        else:\n",
        "            arm_len = full_zone_depth\n",
        "\n",
        "        #####print(arm_len)\n",
        "\n",
        "        # create empty matrix and populate with sums for each consecutive zone\n",
        "        zone_mat = np.zeros((mesh_x, mesh_y))\n",
        "        for col in range(0, mesh_y):\n",
        "            for row in range(0, mesh_x):\n",
        "\n",
        "                from_bottom = mesh_x-row-1\n",
        "                from_right = mesh_y-col-1\n",
        "\n",
        "                bottom_dist = min(from_bottom, arm_len)\n",
        "                top_dist = min(row, arm_len)\n",
        "                left_dist = min(col, arm_len)\n",
        "                right_dist = min(from_right, arm_len)\n",
        "\n",
        "                qgen_zone = qgen_mat[row-top_dist:row+bottom_dist+1, col-left_dist:col+right_dist+1]\n",
        "\n",
        "                # added in the +1s to include symmetrical zones\n",
        "                if circle_zones == True:\n",
        "\n",
        "                    pad_dist_b = arm_len - bottom_dist  # all of these can be 0 if dist = arm_len\n",
        "                    pad_dist_t = arm_len - top_dist\n",
        "                    pad_dist_l = arm_len - left_dist\n",
        "                    pad_dist_r = arm_len - right_dist\n",
        "\n",
        "                    padded_zone = qgen_zone.copy()\n",
        "\n",
        "                    if pad_dist_b != 0:\n",
        "                        pad_mat_b = np.zeros((pad_dist_b, padded_zone.shape[1]))\n",
        "                        padded_zone = np.vstack((padded_zone, pad_mat_b))\n",
        "\n",
        "                    if pad_dist_t != 0:\n",
        "                        pad_mat_t = np.zeros((pad_dist_t, padded_zone.shape[1]))\n",
        "                        padded_zone = np.vstack((pad_mat_t, padded_zone))\n",
        "\n",
        "                    if pad_dist_l != 0:\n",
        "                        pad_mat_l = np.zeros((padded_zone.shape[0], pad_dist_l))\n",
        "                        padded_zone = np.hstack((pad_mat_l, padded_zone)) \n",
        "                    \n",
        "\n",
        "                    if pad_dist_r != 0:\n",
        "                        pad_mat_r = np.zeros((padded_zone.shape[0], pad_dist_r))\n",
        "                        padded_zone = np.hstack((padded_zone, pad_mat_r))\n",
        "\n",
        "\n",
        "                    #pass                                 \n",
        "                    qgen_zone = padded_zone   \n",
        "                    a = np.ones((qgen_zone.shape[0],qgen_zone.shape[1]))\n",
        "                    b = np.reshape(np.arange(1,qgen_zone.shape[0]+1),(-1,1))\n",
        "                    #b2 = np.reshape(np.arange(1,qgen_zone.shape[1]+1),(1,-1))\n",
        "                    \n",
        "                    rowset = a*b\n",
        "                    colset = a*b.T\n",
        "                    dist = ((rowset-qgen_zone.shape[0]/2-.5)**2+(colset-qgen_zone.shape[1]/2-.5)**2)**.5\n",
        "                    qgen_zone[dist>qgen_zone.shape[0]/2+circzone_shift] = 0\n",
        "\n",
        "\n",
        "\n",
        "                zone_mat[row, col] = np.sum(qgen_zone[:]) #- qgen_mat[row, col, -1]  # subtract out its own value\n",
        "\n",
        "        # modify the zone size for subsequent runs if conditions are met\n",
        "        if zone_exp and zone_num%zone_jump == 0: \n",
        "            if zone_num > delay_jump:                       \n",
        "                zone_depth += zone_increase\n",
        "            \n",
        "            full_zone_depth += zone_depth\n",
        "            \n",
        "\n",
        "        zone_list.append(zone_mat)\n",
        "\n",
        "    # subtract smaller zones from larger zones to isolate the larger zone\n",
        "    num_zone = len(zone_list)\n",
        "    for i in range(0,num_zone-1):\n",
        "        zone_list[num_zone-i-1] = zone_list[num_zone-i-1] - zone_list[num_zone-i-2]\n",
        "\n",
        "    zone_list[0] = zone_list[0] - qgen_mat[:,:]  # want to subtract out the value of the element in row, col since that feature is already captured\n",
        "\n",
        "    return zone_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "cellView": "form",
        "id": "lttCKFfctTzD"
      },
      "outputs": [],
      "source": [
        "#@title addQgenZones\n",
        "def addQgenZones(training_data, zone_list, mesh_x=60, mesh_y=118, num_zones = 3, zone_depth = 3):\n",
        "    last_feat = training_data.shape[1] - 2  # get last column index\n",
        "    num_points = training_data.shape[0]\n",
        "    num_elem = mesh_x*mesh_y\n",
        "\n",
        "    input_data = training_data[:,:-1]\n",
        "    label_data = training_data[:,-1]\n",
        "    label_data=np.reshape(label_data, (-1,1))\n",
        "\n",
        "\n",
        "    for i in range(0, len(zone_list)):\n",
        "        counter = 0\n",
        "        new_feature_col = np.zeros((num_points,1))\n",
        "        zone_mat = zone_list[i]\n",
        "        for col in range(0, mesh_y):\n",
        "            for row in range(0, mesh_x):\n",
        "                # current element temperature\n",
        "                new_feature_col[counter:num_points:num_elem, 0] = zone_mat[row,col]\n",
        "\n",
        "                # counter represents the element that you are on\n",
        "                counter+=1\n",
        "\n",
        "        input_data = np.append(input_data, new_feature_col, axis=1)\n",
        "\n",
        "    #print(input_data.shape)\n",
        "    #print(label_data.shape)\n",
        "\n",
        "    training_data = np.append(input_data, label_data, axis=1)\n",
        "    return training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "cellView": "form",
        "id": "wE8KP-PpECMc"
      },
      "outputs": [],
      "source": [
        "#@title addQgenZonesPredict\n",
        "def addQgenZonesPredict(prediction_data, zone_list, mesh_x=60, mesh_y=118, num_zones = 3, zone_depth = 3):\n",
        "    last_feat = prediction_data.shape[1] - 2  # get last column index\n",
        "    num_points = prediction_data.shape[0]\n",
        "    num_elem = mesh_x*mesh_y\n",
        "\n",
        "    #input_data = training_data[:,:-1]\n",
        "    #label_data = training_data[:,-1]\n",
        "    #label_data=np.reshape(label_data, (-1,1))\n",
        "\n",
        "    for i in range(0, len(zone_list)):\n",
        "        counter = 0\n",
        "        new_feature_col = np.zeros((num_points,1))\n",
        "        zone_mat = zone_list[i]\n",
        "        for col in range(0, mesh_y):\n",
        "            for row in range(0, mesh_x):\n",
        "                # current element temperature\n",
        "                new_feature_col[counter, 0] = zone_mat[row,col]\n",
        "\n",
        "                # counter represents the element that you are on\n",
        "                counter+=1\n",
        "        prediction_data = np.append(prediction_data, new_feature_col, axis=1)\n",
        "        #input_data = np.append(input_data, new_feature_col, axis=1)\n",
        "\n",
        "    #print(input_data.shape)\n",
        "    #print(label_data.shape)\n",
        "\n",
        "    #training_data = np.append(input_data, label_data, axis=1)\n",
        "    return prediction_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "DBVepblY82gi"
      },
      "outputs": [],
      "source": [
        "#@title Import Densification Curves\n",
        "def import_dens_curves(temp_list = ['450', '500', '550']):\n",
        "\n",
        "    dens_curve_dict = {}\n",
        "    for temp in temp_list:\n",
        "        name = temp + 'C_densityInfo.txt'\n",
        "        dens_data = import_data(filepath, name, sep='\\t')  \n",
        "        dens_curve_dict[temp] = dens_data[1:,:].astype(float)  \n",
        "\n",
        "    return dens_curve_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "OMc_SEs4826A"
      },
      "outputs": [],
      "source": [
        "#@title sintered_check (turn on sintering)\n",
        "def sintered_check(sinter_hist, temp_mat, sinter_thresh = 450):\n",
        "    sinter_hist[(temp_mat>sinter_thresh)&(sinter_hist<0)] = 0  \n",
        "\n",
        "    return sinter_hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "SdL09WMn3HEZ"
      },
      "outputs": [],
      "source": [
        "#@title update_history\n",
        "def update_history(sinter_hist, sinter_time, temp_mat, sinter_thresh):\n",
        "    sinter_hist[(sinter_hist>=0)&(temp_mat>sinter_thresh)] = sinter_hist[(sinter_hist>=0)&(temp_mat>sinter_thresh)] + sinter_time\n",
        "    return sinter_hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "e7Tm3L2N9JI1"
      },
      "outputs": [],
      "source": [
        "#@title temptime2dens\n",
        "def temptime2dens(dens_mat, temp_mat, sinter_hist, dens_curve_dict, sinter_thresh = 450, laser2oven = 33, dens_init = 2600, mesh_x = 60, mesh_y = 118):\n",
        "\n",
        "    temp_curve_array = np.array([int(i) for i in dens_curve_dict.keys()])\n",
        "    num_curves = temp_curve_array.shape[0]\n",
        "\n",
        "    dens_mat_new = np.zeros((mesh_x, mesh_y)) + dens_init    \n",
        "    current_times = sinter_hist*laser2oven\n",
        "\n",
        "    # perform time interpolation for each available density curve\n",
        "    dens_interp_dict = {}\n",
        "    temp_curve_list = []\n",
        "\n",
        "    dens_mat_temp = np.zeros((mesh_x, mesh_y, num_curves))\n",
        "    for row in range(0, mesh_x):\n",
        "        for col in range(0, mesh_y):\n",
        "            counter = 0\n",
        "            for density_info in dens_curve_dict.values():                \n",
        "                dens_mat_temp[row, col, counter] = np.interp(current_times[row, col], density_info[:,0], density_info[:,1])\n",
        "                counter+=1\n",
        "\n",
        "\n",
        "    dens_interp_array = dens_mat_temp #np.array(dens_interp_list)\n",
        "    temp_curve_array = np.array([int(i) for i in dens_curve_dict.keys()])\n",
        "\n",
        "    max_temp = np.amax(temp_curve_array) # this one is corret! Using 450 now because data was generated incorrectly with 450  # FOR VAL, AND ANYTHING NOT ORIGINAL\n",
        "    #max_temp = 450  # FOR ORIGINAL!!!\n",
        "\n",
        "    temperature_mat = temp_mat.copy()\n",
        "    temperature_mat[temperature_mat > max_temp] = max_temp\n",
        "\n",
        "    # use the time interp reults to interpolate for element temperature\n",
        "    for row in range(0, mesh_x):\n",
        "        for col in range(0, mesh_y):\n",
        "            np.array([])\n",
        "            dens_mat_new[row, col] = np.interp(temperature_mat[row, col], temp_curve_array, dens_interp_array[row,col,:])\n",
        "\n",
        "    # instead of this...\n",
        "    # re-set base density for unsintered elements \n",
        "    #dens_mat[sinter_hist<0] = dens_init\n",
        "    # ... do this\n",
        "    dens_mat[temp_mat > sinter_thresh] = dens_mat_new[temp_mat > sinter_thresh]\n",
        "\n",
        "    # cap the min and max of density\n",
        "    dens_min = 2600\n",
        "    dens_max = 6000\n",
        "    dens_mat[dens_mat<dens_min] = dens_min\n",
        "    dens_mat[dens_mat>dens_max] = dens_max\n",
        "\n",
        "    return dens_mat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "2_izW9rukbP6"
      },
      "outputs": [],
      "source": [
        "#@title get_distance_sum\n",
        "\n",
        "def get_distance_sum(mask_mat, elem_coords):\n",
        "    row, col = elem_coords\n",
        "    a = np.ones((mask_mat.shape[0],mask_mat.shape[1]))\n",
        "    br = np.reshape(np.arange(1,mask_mat.shape[0]+1),(-1,1))\n",
        "    bc = np.reshape(np.arange(1,mask_mat.shape[1]+1),(1,-1))\n",
        "\n",
        "    rowset = a*br\n",
        "    colset = a*bc\n",
        "    dist = ((rowset-row-.5)**2+(colset-col-.5)**2)**.5\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "TnXKOg7ZkcTD"
      },
      "outputs": [],
      "source": [
        "#@title get_qgen_dist\n",
        "def get_qgen_dist(mask_mat, mesh_x = 60, mesh_y = 118, dist_exp = 1.0):\n",
        "    \n",
        "    qgen_dist = np.zeros((mesh_x, mesh_y))\n",
        "    for col in range(0, mesh_y):\n",
        "        for row in range(0, mesh_x):\n",
        "            dist_mat = get_distance_sum(mask_mat, (row,col))\n",
        "\n",
        "            inv_dist_mat = 1/(dist_mat**dist_exp)\n",
        "            qgen_dist[row, col] = np.sum(mask_mat*inv_dist_mat)\n",
        "\n",
        "    return qgen_dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "2brM_8ToGMCy"
      },
      "outputs": [],
      "source": [
        "#@title update_density\n",
        "def update_density(dens_mat, temp_mat, sinter_hist, dens_curve_dict, sinter_time = .2, sinter_thresh = 450):\n",
        "\n",
        "    # check to see which elements have reached the sintering threshold\n",
        "    sinter_hist = sintered_check(sinter_hist, temp_mat)\n",
        "\n",
        "    # update sintering history by adding delta t from the previous timestep\n",
        "    sinter_hist = update_history(sinter_hist, sinter_time, temp_mat, sinter_thresh)\n",
        "    dens_mat = temptime2dens(dens_mat, temp_mat, sinter_hist, dens_curve_dict)\n",
        "\n",
        "    return dens_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF105V5NPkng"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "78untaNRVfkc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "0ae85ca0-da35-4404-fc54-0922998cde0a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-3c948a5adb31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_img_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print(mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtemp_data_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdens_data_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdens_change_data_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqgen_data_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_diff_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetFeaturesFromMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_ls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mlast_val_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-b7ea3b95166e>\u001b[0m in \u001b[0;36mgetFeaturesFromMask\u001b[0;34m(filepath, train_img, num_time, num_ls)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdens_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'density_filt_'\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mtrain_img\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mqgen_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'qgen_norm_filt_'\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mtrain_img\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtemp_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateTemperatureMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdens_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateFeatureMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdens_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_ls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# currently not running for ts=240, ls=9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mqgen_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateFeatureMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqgen_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_ls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-2e40f02c9246>\u001b[0m in \u001b[0;36mcreateTemperatureMatrix\u001b[0;34m(filepath, img_string, num_ls, ls_time, start_ts, mesh_x, mesh_y, num_time, x_min, x_max, y_min, y_max, z_min)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0melem_loc_array\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mimport_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_coords_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mfull_timeseries\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mimport_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeseries_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# split full timeseries into times and temps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-94dbd853390c>\u001b[0m in \u001b[0;36mimport_data\u001b[0;34m(filepath, name, sep)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimport_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'       |      |     |    |   |  | '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0;34m\"\"\"Returns imported data\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36m_get_lines\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m                         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m                             \u001b[0mnew_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_iter_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m                             \u001b[0mrows\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36m_next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;31m# assert for mypy, data is Iterator[str] or None, would error in next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m             \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m()\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title Get Mesh Form Data for all Features (Training)\n",
        "# generate all data for the full set of training masks\n",
        "# 1:37 ofr 3 masks\n",
        "\n",
        "if task == 'train':\n",
        "\n",
        "    temp_data_dict = {}\n",
        "    qgen_data_dict = {}\n",
        "    dens_data_dict = {}\n",
        "    dens_change_data_dict = {}\n",
        "    time_diff_dict = {}\n",
        "    time_dict = {}\n",
        "\n",
        "    last_val_list = []\n",
        "    for mask in train_img_list:\n",
        "        #print(mask)\n",
        "        temp_data_dict[mask], dens_data_dict[mask], dens_change_data_dict[mask], qgen_data_dict[mask], last_val, time_diff_dict[mask], time_dict[mask] = getFeaturesFromMask(filepath, mask, num_time, num_ls)\n",
        "        last_val_list.append(last_val)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipk2IcLzpUYw"
      },
      "outputs": [],
      "source": [
        "#@title Get Mesh Form Data for Qgen Distance Feature (Training)\n",
        "# 15s for the single mask\n",
        "\n",
        "if task == 'train':\n",
        "\n",
        "    if mesh_y<mesh_x:\n",
        "        mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "    qgen_dist_dict = {}\n",
        "\n",
        "    for mask in train_img_list:\n",
        "        mask_mat_train = qgen_data_dict[mask][:,:,0]\n",
        "        qgen_dist_dict[mask] = get_qgen_dist(mask_mat_train, mesh_x=mesh_x, mesh_y=mesh_y, dist_exp = dist_exp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9m3i7tcIiAq"
      },
      "outputs": [],
      "source": [
        "#@title Get Mesh Form Data for all Features (Known FEA Data)\n",
        "# generate all data for the full set of training masks \n",
        "# ~20-25s, 37 seconds recently\n",
        "\n",
        "temp_data_dict_compare = {}\n",
        "qgen_data_dict_compare = {}\n",
        "dens_data_dict_compare = {}\n",
        "dens_change_data_dict_compare = {}\n",
        "time_diff_dict_compare = {}\n",
        "time_dict_compare = {}\n",
        "last_val_list_compare = []\n",
        "\n",
        "for mask in pred_img_list:\n",
        "    temp_data_dict_compare[mask], dens_data_dict_compare[mask], dens_change_data_dict_compare[mask], qgen_data_dict_compare[mask], last_val, time_diff_dict_compare[mask], time_dict_compare[mask] = getFeaturesFromMask(filepath, mask, num_time, num_ls)\n",
        "    last_val_list_compare.append(last_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ms_hPWGvxYy"
      },
      "outputs": [],
      "source": [
        "#@title Get Full Mask from Mask List\n",
        "\n",
        "qgen_data_dict_maskset = {}\n",
        "start_ls = 0\n",
        "mask2_counter = 0\n",
        "for mask_2 in mask_list:    \n",
        "    \n",
        "    qgen_data_dict_maskset[mask_2] = getQgenFromMask(filepath, mask_2, num_time, num_ls, time_dict_compare[pred_img_list[0]], start_ls = start_ls, ls_duration = 1)\n",
        "    new_mask = qgen_data_dict_maskset[mask_2]\n",
        "    \n",
        "    start_ls += 1  # 1 will be replaced by the previous mask's duration \n",
        "\n",
        "    if mask2_counter != 0:\n",
        "           \n",
        "        new_mask = np.concatenate([prev_mask, new_mask],axis=2)\n",
        "\n",
        "    prev_mask = new_mask\n",
        "    \n",
        "    mask2_counter+=1\n",
        "\n",
        "qgen_full_maskset = new_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuEwDornxIq9"
      },
      "outputs": [],
      "source": [
        "#print(qgen_data_dict_maskset[mask_2].shape)\n",
        "print(qgen_full_maskset.shape) # CHECK HERE FIRST IF ANYTHING IS WRONG WITH THE FULL MASK SET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnpwXnVQjchf"
      },
      "outputs": [],
      "source": [
        "#@title Get Mesh Data for Qgen Distance Feature (Predict)\n",
        "if mesh_y<mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "qgen_dist_dict_compare = {}\n",
        "for mask in pred_img_list:\n",
        "    mask_mat_comp = qgen_data_dict_compare[mask][:,:,0]\n",
        "    qgen_dist_dict_compare[mask] = get_qgen_dist(mask_mat_comp, mesh_x=mesh_x, mesh_y=mesh_y, dist_exp = 1.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEqwHsBapGQ-"
      },
      "outputs": [],
      "source": [
        "#@title Get Mesh Data for Qgen Distance Feature (Predict, FULL MASK)\n",
        "if mesh_y<mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "qgen_dist_dict_maskset = {}\n",
        "mask2_counter = 0\n",
        "\n",
        "for mask_2 in mask_list:\n",
        "\n",
        "    num_repeat = qgen_data_dict_maskset[mask_2].shape[2]\n",
        "\n",
        "    mask_mat_ms = qgen_data_dict_maskset[mask_2][:,:,0]\n",
        "    mask_dist = get_qgen_dist(mask_mat_ms, mesh_x=mesh_x, mesh_y=mesh_y, dist_exp = 1.2)\n",
        "    \n",
        "    mask_dist = mask_dist.reshape(mask_dist.shape[0], mask_dist.shape[1],1)\n",
        "    \n",
        "    qgen_dist_dict_maskset[mask_2] = np.repeat(mask_dist, num_repeat,axis=2) \n",
        "\n",
        "    new_mask_dist = qgen_dist_dict_maskset[mask_2]\n",
        "\n",
        "    if mask2_counter != 0:\n",
        "           \n",
        "        new_mask_dist = np.concatenate([prev_mask_dist, new_mask_dist],axis=2)\n",
        "\n",
        "    prev_mask_dist = new_mask_dist\n",
        "    \n",
        "    mask2_counter+=1\n",
        "\n",
        "    #print(qgen_dist_dict_maskset[mask_2].shape)\n",
        "\n",
        "qgen_dist_full_maskset = new_mask_dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjKzrOrpP9xd"
      },
      "outputs": [],
      "source": [
        "qgen_dist_full_maskset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_ZMvgD195wN"
      },
      "outputs": [],
      "source": [
        "#@title Plot Qgen Feature FULL MASK SET\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y if needed\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "temp_plot_interval = .1\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "zone = 5\n",
        "\n",
        "temp_max = np.amax(qgen_full_maskset)\n",
        "#temp_max = np.amax(temp_data_dict['yinyang'][:])\n",
        "upper_temp = 1 #math.ceil(temp_max/temp_plot_interval)*temp_plot_interval\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "Z = qgen_full_maskset[:,:,-17*6]  #np.sqrt(X**2 + Y**2)\n",
        "Z = np.flip(Z,axis=0)\n",
        "#Z = temp_data_dict['yinyang'][:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "\n",
        "fig,ax=plt.subplots(1,1)\n",
        "cp = ax.contourf(X, Y, Z, levels=list(np.arange(0,upper_temp+temp_plot_interval,temp_plot_interval)))\n",
        "fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('Qgen Dist Features: Prediction Mask')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "ax.set_xlabel('X Position (mm)')\n",
        "ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax.set_yticklabels(y_values.round(2))\n",
        "\n",
        "#fig.clim(0, 1000)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gg02s_vq8eNo"
      },
      "outputs": [],
      "source": [
        "#@title Plot Qgen Dist Feature FULL MASK SET\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y if needed\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "temp_plot_interval = 5/2\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "zone = 5\n",
        "\n",
        "temp_max = np.amax(qgen_dist_full_maskset)\n",
        "#temp_max = np.amax(temp_data_dict['yinyang'][:])\n",
        "upper_temp = math.ceil(temp_max/temp_plot_interval)*temp_plot_interval\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "Z = qgen_dist_full_maskset[:,:,15]  #np.sqrt(X**2 + Y**2)\n",
        "Z = np.flip(Z,axis=0)\n",
        "#Z = temp_data_dict['yinyang'][:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "\n",
        "fig,ax=plt.subplots(1,1)\n",
        "cp = ax.contourf(X, Y, Z, levels=list(np.arange(0,upper_temp+temp_plot_interval,temp_plot_interval)))\n",
        "fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('Qgen Dist Features: Prediction Mask')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "ax.set_xlabel('X Position (mm)')\n",
        "ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax.set_yticklabels(y_values.round(2))\n",
        "\n",
        "#fig.clim(0, 1000)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1R5cfSz8epH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enf_Itpt01L0"
      },
      "outputs": [],
      "source": [
        "#@title Plot Qgen Dist Feature\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y if needed\n",
        "if mesh_y<mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "mask_mat = qgen_data_dict_compare[mask][:,:,0]\n",
        "qgen_dist = get_qgen_dist(mask_mat, mesh_x=mesh_x, mesh_y=mesh_y, dist_exp = dist_exp)\n",
        "\n",
        "\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "qgen_dist = qgen_dist**(1/1)\n",
        "\n",
        "temp_plot_interval = 5/2\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "zone = 5\n",
        "\n",
        "temp_max = np.amax(qgen_dist)\n",
        "#temp_max = np.amax(temp_data_dict['yinyang'][:])\n",
        "upper_temp = math.ceil(temp_max/temp_plot_interval)*temp_plot_interval\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "Z = qgen_dist  #np.sqrt(X**2 + Y**2)\n",
        "Z = np.flip(Z,axis=0)\n",
        "#Z = temp_data_dict['yinyang'][:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "\n",
        "fig,ax=plt.subplots(1,1)\n",
        "cp = ax.contourf(X, Y, Z, levels=list(np.arange(0,upper_temp+temp_plot_interval,temp_plot_interval)))\n",
        "fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('Qgen Dist Features: Prediction Mask')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "ax.set_xlabel('X Position (mm)')\n",
        "ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax.set_yticklabels(y_values.round(2))\n",
        "\n",
        "#fig.clim(0, 1000)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkmZHmiftjpO"
      },
      "outputs": [],
      "source": [
        "#qgen_dist_mat_train = np.repeat(qgen_dist_dict_compare[mask][:, :, np.newaxis], 135, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMsyb-Rk3yBV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Convert Mesh Form Data into Full Training Dataset\n",
        "# Add density in later\n",
        "\n",
        "if task == 'train':\n",
        "\n",
        "    qgen_zone_list_dict = {}\n",
        "\n",
        "    temp_list = []\n",
        "    qgen_list = []\n",
        "\n",
        "    mask_counter = 0\n",
        "    for mask in train_img_list:\n",
        "        #print(mask_counter)\n",
        "\n",
        "        last_val_list[mask_counter] = 240\n",
        "\n",
        "        # restrict the full dataset to a subset of the transient time window\n",
        "        if last_val_list[mask_counter] > train_ts and time_subset == True:\n",
        "            last_val_list[mask_counter] = train_ts\n",
        "\n",
        "            temp_data_dict[mask] = temp_data_dict[mask][:,:,:train_ts]\n",
        "            qgen_data_dict[mask] = qgen_data_dict[mask][:,:,:train_ts]\n",
        "            dens_data_dict[mask] = dens_data_dict[mask][:,:,:train_ts]\n",
        "            dens_change_data_dict[mask] = dens_change_data_dict[mask][:,:,:train_ts]\n",
        "\n",
        "            print(time_diff_dict[mask].shape)\n",
        "            time_diff_dict[mask] = time_diff_dict[mask][:train_ts-1]\n",
        "            time_dict[mask] = time_dict[mask][:train_ts]\n",
        "            print(time_diff_dict[mask].shape)\n",
        "\n",
        "\n",
        "        # get temperature data\n",
        "        if single_temp == True:\n",
        "            temp_training_data = getAdjacentSingle(temp_data_dict[mask], last_val_list[mask_counter], mesh_x=60, mesh_y=118)\n",
        "        else:\n",
        "            temp_training_data, tme = getAdjacentFeatures(temp_data_dict[mask], last_val_list[mask_counter], num_adjacent = num_adjacent, udrl = udrl)    \n",
        "        \n",
        "        #temp_list.append(tme)\n",
        "        #print(temp_training_data.shape)\n",
        "\n",
        "        # get qgen data\n",
        "        if single_qgen == True:\n",
        "            qgen_training_data = getAdjacentSingle(qgen_data_dict[mask], last_val_list[mask_counter], mesh_x=60, mesh_y=118)\n",
        "        else:\n",
        "            qgen_training_data, temp_mat_exp = getAdjacentFeatures(qgen_data_dict[mask], last_val_list[mask_counter],num_adjacent = num_adjacent, udrl = udrl)\n",
        "        \n",
        "        # get dens data\n",
        "        if single_dens == True:\n",
        "            dens_training_data = getAdjacentSingle(dens_data_dict[mask], last_val_list[mask_counter], mesh_x=60, mesh_y=118)\n",
        "        else:\n",
        "            dens_training_data, temp_mat_exp = getAdjacentFeatures(dens_data_dict[mask], last_val_list[mask_counter],num_adjacent = num_adjacent, udrl = udrl)\n",
        "        \n",
        "        # get desnity change data\n",
        "        if single_dens_change == True:\n",
        "            dens_change_training_data = getAdjacentSingle(dens_change_data_dict[mask], last_val_list[mask_counter], mesh_x=60, mesh_y=118)\n",
        "        else:\n",
        "            dens_change_training_data, temp_mat_exp = getAdjacentFeatures(dens_change_data_dict[mask], last_val_list[mask_counter],num_adjacent = num_adjacent, udrl = udrl)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # get qgen dist feature in mesh form\n",
        "        qgen_dist_mat = np.repeat(qgen_dist_dict[mask][:, :, np.newaxis], temp_data_dict[mask].shape[2], axis=2)\n",
        "        # get qgen dist data\n",
        "        if single_qgen_dist == True:\n",
        "            qgen_dist_training_data = getAdjacentSingle(qgen_dist_mat, last_val_list[mask_counter], mesh_x=60, mesh_y=118)\n",
        "        else:\n",
        "            qgen_dist_training_data, temp_mat_exp = getAdjacentFeatures(qgen_dist_mat, last_val_list[mask_counter],num_adjacent = num_adjacent, udrl = udrl)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        #qgen_list.append(temp_mat_exp)\n",
        "\n",
        "        label_data = getTemperatureLabels(temp_data_dict[mask], last_val_list[mask_counter])\n",
        "        \n",
        "        # handle the time delta feature\n",
        "        if incl_time == True:\n",
        "            #print('Time Array Shape: ')\n",
        "            #print(time_diff_dict[mask].shape)\n",
        "            #print(time_diff_dict[mask].shape)\n",
        "            #print(last_val_list[mask_counter])\n",
        "            time_diff_data = get_time_feat(time_diff_dict[mask], mesh_x, mesh_y, last_val_list[mask_counter])\n",
        "            time_data = get_time_feat(time_dict[mask][:-1], mesh_x, mesh_y, last_val_list[mask_counter])\n",
        "            #mask_training_data = np.hstack((temp_training_data, qgen_training_data, qgen_dist_training_data, dens_training_data, dens_change_training_data, time_diff_data, label_data))\n",
        "            mask_training_data = np.hstack((temp_training_data, qgen_training_data, qgen_dist_training_data, dens_training_data, time_diff_data, label_data)) # reserved for BIS (all BIS)\n",
        "            #mask_training_data = np.hstack((temp_training_data, qgen_training_data, qgen_dist_training_data, dens_training_data, dens_change_training_data, time_diff_data, time_data ,label_data))\n",
        "            #mask_training_data = np.hstack((temp_training_data, qgen_training_data, dens_training_data, dens_change_training_data, time_diff_data, time_data ,label_data))\n",
        "            #mask_training_data = np.hstack((temp_training_data, qgen_training_data, dens_training_data, dens_change_training_data, time_diff_data, label_data))\n",
        "\n",
        "\n",
        "        else:\n",
        "            mask_training_data = np.hstack((temp_training_data, qgen_training_data, dens_training_data, dens_change_training_data, label_data))\n",
        "\n",
        "        #print(mask_training_data.shape)\n",
        "\n",
        "        # toggle for qgen_zones\n",
        "        qgen_zone_list_dict[mask] = getQgenZones(qgen_data_dict[mask][:,:,-1], mesh_x=60, mesh_y=118, num_zones = num_zones, zone_depth = zone_depth, delay_jump = delay_jump, circle_zones = circle_zones, zone_exp = zone_exp)    \n",
        "        if qgen_zones == True:\n",
        "            mask_training_data = addQgenZones(mask_training_data, qgen_zone_list_dict[mask], mesh_x=60, mesh_y=118, num_zones = num_zones, zone_depth = zone_depth)\n",
        "\n",
        "        if mask_counter !=0:\n",
        "            mask_training_data = np.vstack((mask_training_data_prev, mask_training_data))\n",
        "\n",
        "        mask_training_data_prev = mask_training_data\n",
        "        mask_counter+=1\n",
        "\n",
        "    training_data = mask_training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJUay5xc_GrO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Convert Mesh Form Data into Initial Prediction Dataset (WATCH THIS ONE IF ERRORS)\n",
        "# Add density in later\n",
        "\n",
        "#pred_start = 80  # for testing only\n",
        "\n",
        "temp_list2 = []\n",
        "\n",
        "mask_counter = 0\n",
        "for mask in pred_img_list:\n",
        "    print(mask_counter)\n",
        "\n",
        "    if last_val_list_compare[mask_counter] > train_ts and time_subset == True:\n",
        "        last_val_list_compare[mask_counter] = train_ts\n",
        "\n",
        "        temp_data_dict_compare[mask] = temp_data_dict_compare[mask][:,:,:train_ts]\n",
        "        qgen_data_dict_compare[mask] = qgen_data_dict_compare[mask][:,:,:train_ts]\n",
        "        dens_data_dict_compare[mask] = dens_data_dict_compare[mask][:,:,:train_ts]\n",
        "        dens_change_data_dict_compare[mask] = dens_change_data_dict_compare[mask][:,:,:train_ts]\n",
        "\n",
        "        time_diff_dict_compare[mask] = time_diff_dict_compare[mask][:train_ts-1]\n",
        "        time_dict_compare[mask] = time_dict_compare[mask][:train_ts]\n",
        "\n",
        "    # temperature data\n",
        "    if single_temp == True:\n",
        "        temp_prediction_data = getAdjacentSinglePredict(temp_data_dict_compare[mask][:,:,pred_start], last_val_list_compare[mask_counter], mesh_x=60, mesh_y=118)\n",
        "    else:\n",
        "        temp_prediction_data, tme = getAdjacentFeaturesPredict(temp_data_dict_compare[mask][:,:,pred_start], last_val_list_compare[mask_counter],num_adjacent = num_adjacent, udrl=udrl)    \n",
        "    \n",
        "    #temp_list2.append(tme)\n",
        "    \n",
        "\n",
        "    #\n",
        "    #\n",
        "    # qgen data\n",
        "    if single_qgen == True:\n",
        "        qgen_prediction_data = getAdjacentSinglePredict(qgen_full_maskset[:,:,pred_start], last_val_list_compare[mask_counter], mesh_x=60, mesh_y=118)\n",
        "    else:\n",
        "        qgen_prediction_data, temp_mat_exp = getAdjacentFeaturesPredict(qgen_full_maskset[:,:,pred_start], last_val_list_compare[mask_counter],num_adjacent = num_adjacent, udrl = udrl)    \n",
        "\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "\n",
        "    # density data\n",
        "    if single_dens == True:\n",
        "        dens_prediction_data = getAdjacentSinglePredict(dens_data_dict_compare[mask][:,:,pred_start], last_val_list_compare[mask_counter], mesh_x=60, mesh_y=118)\n",
        "    else:\n",
        "        dens_prediction_data, temp_mat_exp = getAdjacentFeaturesPredict(dens_data_dict_compare[mask][:,:,pred_start], last_val_list_compare[mask_counter],num_adjacent = num_adjacent, udrl = udrl)    \n",
        "    \n",
        "    # density change data\n",
        "    if single_dens_change == True:\n",
        "        dens_change_prediction_data = getAdjacentSinglePredict(dens_change_data_dict_compare[mask][:,:,pred_start], last_val_list_compare[mask_counter], mesh_x=60, mesh_y=118)\n",
        "    else:\n",
        "        dens_change_prediction_data, temp_mat_exp = getAdjacentFeaturesPredict(dens_change_data_dict_compare[mask][:,:,pred_start], last_val_list_compare[mask_counter],num_adjacent = num_adjacent, udrl = udrl)    \n",
        "\n",
        "\n",
        "\n",
        "    #\n",
        "    #\n",
        "    # get qgen dist feature in mesh form\n",
        "    qgen_dist_mat_compare = np.repeat(qgen_dist_dict_compare[mask][:, :, np.newaxis], temp_data_dict_compare[mask].shape[2], axis=2)\n",
        "    # get qgen dist data\n",
        "    if single_qgen_dist == True:\n",
        "        qgen_dist_prediction_data = getAdjacentSinglePredict(qgen_dist_full_maskset[:,:,pred_start], last_val_list_compare[mask_counter], mesh_x=60, mesh_y=118)\n",
        "    else:\n",
        "        qgen_dist_prediction_data, temp_mat_exp = getAdjacentFeaturesPredict(qgen_dist_full_maskset[:,:,pred_start], last_val_list_compare[mask_counter],num_adjacent = num_adjacent, udrl = udrl)\n",
        "    \n",
        "    #\n",
        "    #\n",
        "    #\n",
        "\n",
        "\n",
        "    #temp_list2.append(temp_mat_exp) \n",
        "\n",
        "    # handle the time array    \n",
        "    if incl_time == True:\n",
        "        time_diff_array_pred = get_time_feat_predict(time_diff_dict_compare[mask][pred_start], mesh_x, mesh_y)\n",
        "        time_array_pred = get_time_feat_predict(time_dict_compare[mask][pred_start], mesh_x, mesh_y)\n",
        "        \n",
        "        #mask_prediction_data = np.hstack((temp_prediction_data, qgen_prediction_data, qgen_dist_prediction_data, dens_prediction_data, dens_change_prediction_data, time_diff_array_pred))\n",
        "        mask_prediction_data = np.hstack((temp_prediction_data, qgen_prediction_data, qgen_dist_prediction_data, dens_prediction_data, time_diff_array_pred)) # reserved for BIS\n",
        "        #mask_prediction_data = np.hstack((temp_prediction_data, qgen_prediction_data, qgen_dist_prediction_data, dens_prediction_data, dens_change_prediction_data, time_diff_array_pred, time_array_pred))\n",
        "        #mask_prediction_data = np.hstack((temp_prediction_data, qgen_prediction_data, dens_prediction_data, dens_change_prediction_data, time_diff_array_pred, time_array_pred))\n",
        "        #mask_prediction_data = np.hstack((temp_prediction_data, qgen_prediction_data, dens_prediction_data, dens_change_prediction_data, time_diff_array_pred))\n",
        "\n",
        "    else:\n",
        "        mask_prediction_data = np.hstack((temp_prediction_data, qgen_prediction_data, dens_prediction_data, dens_change_prediction_data))\n",
        "\n",
        "\n",
        "    #\n",
        "    #\n",
        "    # toggle for qgen_zone features\n",
        "    qgen_zone_list_pred = getQgenZones(qgen_full_maskset[:,:,-1], mesh_x=60, mesh_y=118, num_zones = num_zones, zone_depth = zone_depth, delay_jump = delay_jump, circle_zones = circle_zones, zone_exp = zone_exp)      \n",
        "    if qgen_zones == True:\n",
        "        mask_prediction_data = addQgenZonesPredict(mask_prediction_data, qgen_zone_list_pred, mesh_x=60, mesh_y=118, num_zones = num_zones, zone_depth = zone_depth)\n",
        "    \n",
        "    #\n",
        "    #\n",
        "    #\n",
        "\n",
        "\n",
        "    #qgen_data_dict_compare[mask][:,:,-1] # qgen_zone_list_pred\n",
        "    if mask_counter !=0:\n",
        "        mask_prediction_data = np.vstack((mask_prediction_data_prev, mask_prediction_data))\n",
        "\n",
        "\n",
        "    mask_prediction_data_prev = mask_prediction_data\n",
        "    mask_counter+=1\n",
        "\n",
        "prediction_data = mask_prediction_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Remove Duplicates from training datasets (same starting mask, ect...)\n",
        "\n",
        "if task == 'train':\n",
        "    training_df = pd.DataFrame(training_data)\n",
        "    del training_data\n",
        "    training_df_noDupe = training_df.drop_duplicates(keep='first')\n",
        "    del training_df\n",
        "    training_data = training_df_noDupe.to_numpy()\n",
        "    del training_df_noDupe"
      ],
      "metadata": {
        "id": "1WDtBwTA7gHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ73pYw355OR"
      },
      "outputs": [],
      "source": [
        "#@title Train Test Split    \n",
        "if task == 'train':\n",
        "\n",
        "    # variable and data setup\n",
        "    x=training_data[:,:-1]\n",
        "    y=training_data[:,-1]\n",
        "    del training_data\n",
        "    y=np.reshape(y, (-1,1)) # convert from (n, ) to (n, 1)\n",
        "\n",
        "    # normalize data using sklearn\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "    print(scaler_x.fit(x))\n",
        "    xscale=scaler_x.transform(x)\n",
        "    print(scaler_y.fit(y))\n",
        "    yscale=scaler_y.transform(y)\n",
        "\n",
        "\n",
        "    # split data into training and testing data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(xscale, yscale, test_size=0.2)  # random_state=42\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBxQFryfQocl"
      },
      "outputs": [],
      "source": [
        "#@title Train Neural Network\n",
        "if task == 'train' and model_type == 'nn':\n",
        "    \n",
        "    input_dim = training_data.shape[1]-1\n",
        "    model = Sequential()         #10        \n",
        "    # add additional hidden layers\n",
        "\n",
        "\n",
        "    # setup input layer\n",
        "    if act_fun == 'leaky_relu':\n",
        "        alpha = 0.3\n",
        "        model.add(Dense(num_nodes, input_dim=input_dim, kernel_initializer='normal', activation=tf.keras.layers.LeakyReLU(alpha=alpha)))  # need to go back and add delta_t and delta_rho as the 16th and 17th feature vectors\n",
        "\n",
        "    else:          \n",
        "        model.add(Dense(num_nodes, input_dim=input_dim, kernel_initializer='normal', activation=act_fun))  # need to go back and add delta_t and delta_rho as the 16th and 17th feature vectors\n",
        "\n",
        "\n",
        "    # setup hidden layers\n",
        "    for layer in range(0, num_hidden_layers-1):\n",
        "\n",
        "        if act_fun == 'leaky_relu':\n",
        "            model.add(Dense(num_nodes, activation=tf.keras.layers.LeakyReLU(alpha=alpha)))\n",
        "        else:    \n",
        "            model.add(Dense(num_nodes, activation=act_fun)) # likely 'relu' for here and above\n",
        "    \n",
        "    # add single variable regression output layer\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.summary()\n",
        "\n",
        "    # attempts to adjust model learning rate \n",
        "    #optimizer = keras.optimizers.Adam(lr=0.01)\n",
        "    #optimizer = opt.adam.adam(learning_rate = .01)\n",
        "    #model.compile(loss='mse', optimizer=optimizer, metrics=['mse','mae','accuracy'])\n",
        "\n",
        "\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=['mse','mae','accuracy'])\n",
        "\n",
        "\n",
        "    save_best_model = ModelCheckpoint(filepath, monitor='val_loss', \n",
        "                                      save_best_only=True, save_weights_only=True)\n",
        "\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=12, batch_size=50,  verbose=1, validation_split=0.2, callbacks=[save_best_model])\n",
        "    model.load_weights(filepath)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3dPNNog2FINU"
      },
      "outputs": [],
      "source": [
        "#@title Train XGBoost Model\n",
        "\n",
        "'''\n",
        "    X_train, X_test, y_train, y_test = train_test_split(xscale, yscale, test_size=0.2)  # random_state=42\n",
        "    xgb_params = {\n",
        "        \"n_estimators\": 400,\n",
        "        \"max_depth\": 6,\n",
        "        \"min_samples_split\": 2,\n",
        "        \"learning_rate\": 0.02,\n",
        "        \"loss\": \"squared_error\",\n",
        "        \"verbose\": 2,\n",
        "    }\n",
        "    xgb_cv_params = {\n",
        "        \"n_estimators\": [200,300,400,500],\n",
        "        \"max_depth\": [3,4,5,6,7],\n",
        "        \"min_samples_split\": [5],\n",
        "        \"learning_rate\": [0.01],\n",
        "        \"loss\": [\"squared_error\"],\n",
        "    }\n",
        "    xgb_regr = GradientBoostingRegressor(**xgb_params)\n",
        "    xgb_regr.fit(X_train, y_train)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB4a6JKgmYYb"
      },
      "outputs": [],
      "source": [
        "#@title Train XGBoost (Python)\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "if task == 'train' and model_type == 'xgb':\n",
        "\n",
        "    xgb_regr = xgb.XGBRegressor(**xgb_params)\n",
        "    xgb_regr.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCKJ-3WpzT6h"
      },
      "outputs": [],
      "source": [
        "#@title Train LightGBM (Python)\n",
        "\n",
        "import lightgbm as lgbm\n",
        "\n",
        "if task == 'train' and model_type == 'lgbm':\n",
        "\n",
        "    train_data = lgbm.Dataset(X_train, label=y_train.ravel())\n",
        "    test_data = lgbm.Dataset(X_test, label=y_test.ravel())\n",
        "\n",
        "    parameters = lgbm_params\n",
        "\n",
        "    lgbm_regr = lgbm.train(parameters, \n",
        "                                train_data, \n",
        "                                valid_sets = test_data,\n",
        "                          )\n",
        "                                #num_boost_round = 800)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcvbJuoe03cE"
      },
      "outputs": [],
      "source": [
        "#@title Select ML Model\n",
        "import pickle\n",
        "\n",
        "model_type = model_type\n",
        "model_name = model_name\n",
        "#model_name = '{0}_{1}_elem_{2}by{3}uniform_{4}mask_adj_4deep_expzones_single'.format(type_model, num_adjacent, num_zones, zone_depth, num_mask_train)\n",
        "\n",
        "# BIS FOR ORIGINAL\n",
        "#### model_name  = 'qgen_distance_added_BIS_1_21_alt' # BIS for error (10.45), % error <5%, (extrap) predicted \"all\" very well, but failed on \"plus\"\n",
        "####model_name = 'qgen_distance_added_BIS_1_21' # tied BIS-a, 3x24 NN exp = 1.21,(extrap) predicted \"plus\" fairly well, but failed on \"all\"\n",
        "\n",
        "# BIS FOR VAL\n",
        "####model_name = 'qgen_distance_added_BIS_1_21_val_alt' # same settings as above, just different training and testing data\n",
        "\n",
        "# BIS FOR GRAYSCALE\n",
        "#model_name = 'qgen_distance_added_BIS_1_21_gray2s_16_nodes'\n",
        "\n",
        "####model_name =  'qgen_distance_added' #'qgen_distance_added_singles' # BIS-b 3x24 NN exp = 1.2\n",
        "\n",
        "####model_name = 'qgen_distance_added_single' #3BIS by 1 degree avg avg error 3x24 NN exp = 1.2\n",
        "####model_name = 'qgen_distance_added_BIS2' # 2BIS, exp = 1.2\n",
        "\n",
        "#if task == 'train':\n",
        "#    model.save(filepath + model_name)\n",
        "\n",
        "#joblib.dump(xgb_regr, filepath + model_name)\n",
        "print(model_name)\n",
        "\n",
        "if task == 'train':\n",
        "    joblib.dump(scaler_x, filepath + model_name + '_scalar_x')\n",
        "    joblib.dump(scaler_y, filepath + model_name + '_scalar_y')\n",
        "\n",
        "if task == 'pred':\n",
        "    scaler_x = joblib.load(filepath + model_name + '_scalar_x')\n",
        "    scaler_y = joblib.load(filepath + model_name + '_scalar_y')\n",
        "\n",
        "\n",
        "\n",
        "#type_model = \"random_forest\"\n",
        "if model_type == \"rf\":\n",
        "    #model = rfc_regr\n",
        "    pass\n",
        "elif model_type == \"xgb\":\n",
        "\n",
        "    if task == 'train':\n",
        "        model = xgb_regr\n",
        "        pickle.dump(model, open(filepath + model_name, \"wb\"))\n",
        "    \n",
        "    if task == 'pred':\n",
        "        model = pickle.load(open(filepath + model_name, \"rb\"))\n",
        "\n",
        "elif model_type == \"lgbm\":\n",
        "\n",
        "    if task == 'train':\n",
        "        model = lgbm_regr\n",
        "        pickle.dump(model, open(filepath + model_name, \"wb\"))\n",
        "\n",
        "    if task == 'pred':\n",
        "        model = pickle.load(open(filepath + model_name, \"rb\"))\n",
        "\n",
        "elif model_type == \"nn\":\n",
        "\n",
        "    if task == 'train':\n",
        "        model.save(filepath + model_name)\n",
        "    if task == 'pred':\n",
        "        model = load_model(filepath + model_name)\n",
        "else:\n",
        "    assert False, \"Choose model that has been trained properly\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBmjEJasuJLx"
      },
      "outputs": [],
      "source": [
        "#@title Plot Loss\n",
        "if task == 'train' and model_type == \"nn\":\n",
        "    print(history.history.keys())\n",
        "    # \"Loss\"\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcQs2jV4mJPf"
      },
      "outputs": [],
      "source": [
        "#@title Predict in Mesh Form\n",
        "# ~40s\n",
        "\n",
        "# list of masks to be run through at select timesteps when properties update\n",
        "#mask_list\n",
        "\n",
        "pred_name = pred_img_list[0]\n",
        "\n",
        "if mesh_y<mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "num_time_pred = 131 #num_timesteps #133 #134         # 135\n",
        "num_elem = mesh_x*mesh_y\n",
        "\n",
        "# get initial condition of the predicting mask\n",
        "#INITIAL TEMPERATURE\n",
        "pred_array = prediction_data #[:num_elem,:-1] #prediction_data\n",
        "predicted_temps = np.zeros((mesh_x, mesh_y,num_time_pred + 1))\n",
        "predicted_temps[:,:,:pred_start] = temp_data_dict_compare[pred_name][:,:,:pred_start] # set the predicted temp array to be exactly the true value #temp_init\n",
        "predicted_temps[:,:,pred_start] =  temp_data_dict_compare[pred_name][:,:,pred_start]  # start with a true value   #temp_mat_pred[:,:,0]    # temp_mat_pred\n",
        "\n",
        "#INITIAL DENSITY\n",
        "predicted_dens = np.zeros((mesh_x, mesh_y,num_time_pred + 1)) + dens_init\n",
        "predicted_dens[:,:,:pred_start] = dens_data_dict_compare[pred_name][:,:,:pred_start] # set the predicted temp array to be exactly the true value #temp_init\n",
        "predicted_dens[:,:,pred_start] =  dens_data_dict_compare[pred_name][:,:,pred_start]  # start with a true value   #temp_mat_pred[:,:,0]    # temp_mat_pred\n",
        "\n",
        "#INITIAL DENSITY CHANGE\n",
        "predicted_dens_change = np.zeros((mesh_x, mesh_y,num_time_pred + 1))\n",
        "predicted_dens_change[:,:,:pred_start] = dens_change_data_dict_compare[pred_name][:,:,:pred_start] # set the predicted temp array to be exactly the true value #temp_init\n",
        "predicted_dens_change[:,:,pred_start] =  dens_change_data_dict_compare[pred_name][:,:,pred_start]  # start with a true value   #temp_mat_pred[:,:,0]    # temp_mat_pred\n",
        "\n",
        "# import georgina density curves\n",
        "dens_curve_dict = import_dens_curves()\n",
        "\n",
        "# run full prediction for all timesteps\n",
        "\n",
        "print(pred_array.shape)\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "# ok out here when only one mask is used\n",
        "'''\n",
        "# QGEN FEATURE\n",
        "if single_qgen == True:\n",
        "    qgen_prediction_data = getAdjacentSinglePredict(qgen_data_dict_compare[mask][:,:,-1], last_val_list_compare[0], mesh_x=60, mesh_y=118)\n",
        "else:\n",
        "    qgen_prediction_data, nothing = getAdjacentFeaturesPredict(qgen_data_dict_compare[pred_name][:,:,-1], last_val_list_compare[0],num_adjacent = num_adjacent,  udrl = udrl)\n",
        "\n",
        "# QGEN DIST FEATURE\n",
        "# get qgen dist feature in mesh form\n",
        "qgen_dist_mat_compare = np.repeat(qgen_dist_dict_compare[mask][:, :, np.newaxis], temp_data_dict_compare[mask].shape[2], axis=2)\n",
        "# get qgen dist data\n",
        "if single_qgen_dist == True:\n",
        "    qgen_dist_prediction_data = getAdjacentSinglePredict(qgen_dist_mat_compare[:,:,-1], last_val_list_compare[0], mesh_x=60, mesh_y=118)\n",
        "else:\n",
        "    qgen_dist_prediction_data, temp_mat_exp = getAdjacentFeaturesPredict(qgen_dist_mat_compare[:,:,-1], last_val_list_compare[0],num_adjacent = num_adjacent, udrl = udrl)\n",
        "\n",
        "qgen_zone_list_pred = getQgenZones(qgen_data_dict_compare[pred_name][:,:,-1], mesh_x, mesh_y, num_zones, zone_depth, delay_jump = delay_jump, circle_zones = circle_zones ,zone_exp = zone_exp)\n",
        "\n",
        "'''\n",
        "\n",
        "# create mesh sized sintering tracker\n",
        "\n",
        "if pred_start == 0:\n",
        "    sinter_hist = np.zeros((mesh_x, mesh_y))-1\n",
        "else:\n",
        "    sinter_hist = np.zeros((mesh_x, mesh_y))-1\n",
        "    \n",
        "#mask_index = 0\n",
        "\n",
        "#print(prediction_data[:num_elem,:-1])\n",
        "for ts in range(pred_start,num_time_pred): #num_time_pred-1): #num_time_pred):\n",
        "\n",
        "    # get current time\n",
        "    current_simulation_time = time_dict_compare[mask][ts] #[ts+1]\n",
        "    #cst = current_simulation_time\n",
        "\n",
        "    #print('loop')\n",
        "    Xnew = pred_array\n",
        "    Xnew = scaler_x.transform(Xnew)  # use predetermined scalar to scale new test data\n",
        "    ynew = model.predict(Xnew).reshape(-1,1)\n",
        "    temps = scaler_y.inverse_transform(ynew)   ### YOU MIGHT BE ABLE TO DIRECTLY SET THIS AS TEMP_PREDICTION_DATA\n",
        "\n",
        "    # joblib parallelize ******\n",
        "    counter = 0\n",
        "    for col in range(0,mesh_y):\n",
        "        for row in range(0,mesh_x):\n",
        "            elem = col*mesh_x + row\n",
        "            temp = temps[elem]\n",
        "            predicted_temps[row,col,ts+1] = temp\n",
        "            counter+=1\n",
        "\n",
        "    #print(temp_data_dict_compare[mask].shape)\n",
        "    ####qgen_prediction_data = getAdjacentSinglePredict(qgen_data_dict_compare[mask][:,:,-1], last_val_list_compare[0], mesh_x=60, mesh_y=118)\n",
        "\n",
        "    if single_temp == True:    \n",
        "        temp_prediction_data = getAdjacentSinglePredict(predicted_temps[:,:,ts+1], last_val_list_compare[0], mesh_x=60, mesh_y=118)\n",
        "    else:    \n",
        "        temp_prediction_data, nothing = getAdjacentFeaturesPredict(predicted_temps[:,:,ts+1], last_val_list_compare[0],num_adjacent = num_adjacent, udrl=udrl)\n",
        "    #qgen_prediction_data, nothing = getAdjacentFeaturesPredict(qgen_data_dict_compare[pred_name][:,:,ts+1], last_val_list_compare[0],num_adjacent = num_adjacent)\n",
        "\n",
        "    # handle the addition of the time array feature\n",
        "\n",
        "    # dens_mat, temp_mat, sinter_thresh, sinter_hist, dens_curve_dict, sinter_time = .2\n",
        "    # ADD IN DENSITY AS A FEATURE\n",
        "    \n",
        "    if int(current_simulation_time*10000)%int(sinter_time*10000)==0:  # check to see if timestep is a loadstep (density should update 9 times)                                \n",
        "        predicted_dens[:,:,ts+1] = update_density(predicted_dens[:,:,ts], predicted_temps[:,:,ts+1], sinter_hist, dens_curve_dict, sinter_time = .2, sinter_thresh=450) # sinter time should be a function of total time and number of updates\n",
        "    else:\n",
        "        predicted_dens[:,:,ts+1] = predicted_dens[:,:,ts]\n",
        "    \n",
        "\n",
        "    #predicted_dens[:,:,ts+1] = dens_data_dict_compare[pred_name][:,:,ts+1]\n",
        "\n",
        "    #print('Predicted Dens Shape')\n",
        "    #print(predicted_dens[:,:,ts+1].shape)\n",
        "    #print(ts+1)\n",
        "\n",
        "    if single_dens == True:\n",
        "        dens_prediction_data = getAdjacentSinglePredict(predicted_dens[:,:,ts+1], last_val_list_compare[0], mesh_x=60, mesh_y=118)\n",
        "    else:\n",
        "        dens_prediction_data, temp_mat_exp = getAdjacentFeaturesPredict(predicted_dens[:,:,ts+1], last_val_list_compare[0],num_adjacent = num_adjacent, udrl = udrl)    \n",
        "\n",
        "    # ADD IN DENSITY CHANGE AS A FEATURE\n",
        "    # calculate density change from last timestep\n",
        "    predicted_dens_change[:,:,ts+1] = predicted_dens[:,:,ts+1] - predicted_dens[:,:,ts]\n",
        "\n",
        "    \n",
        "    # get desnity change data in training form\n",
        "    if single_dens_change == True:\n",
        "        dens_change_training_data = getAdjacentSinglePredict(predicted_dens_change[:,:,ts+1], last_val_list_compare[0], mesh_x=60, mesh_y=118)\n",
        "    else:\n",
        "        dens_change_training_data, temp_mat_exp = getAdjacentFeaturesPredict(predicted_dens_change[:,:,ts+1], last_val_list_compare[0],num_adjacent = num_adjacent, udrl = udrl)\n",
        "\n",
        "\n",
        "\n",
        "    # handle time as a feature\n",
        "    if incl_time == True:\n",
        "        time_diff_array_pred = get_time_feat_predict(time_diff_dict_compare[mask][ts+1], mesh_x, mesh_y)\n",
        "        time_array_pred = get_time_feat_predict(time_dict_compare[mask][ts+1], mesh_x, mesh_y)        \n",
        "        #pred_array = np.hstack((temp_prediction_data, qgen_prediction_data, qgen_dist_prediction_data, dens_prediction_data, dens_change_prediction_data, time_diff_array_pred))\n",
        "        pred_array = np.hstack((temp_prediction_data, qgen_prediction_data, qgen_dist_prediction_data, dens_prediction_data, time_diff_array_pred))  # reserved for BIS\n",
        "        #pred_array = np.hstack((temp_prediction_data, qgen_prediction_data, qgen_dist_prediction_data, dens_prediction_data, dens_change_training_data, time_diff_array_pred, time_array_pred))\n",
        "        #pred_array = np.hstack((temp_prediction_data, qgen_prediction_data, dens_prediction_data, dens_change_training_data, time_diff_array_pred, time_array_pred))\n",
        "        #pred_array = np.hstack((temp_prediction_data, qgen_prediction_data, dens_prediction_data, dens_change_training_data, time_diff_array_pred))\n",
        "\n",
        "    else:\n",
        "        pred_array = np.hstack((temp_prediction_data, qgen_prediction_data, dens_prediction_data, dens_change_training_data))\n",
        "\n",
        "\n",
        "    ####qgen_zone_list_pred = getQgenZones(qgen_data_dict_compare[pred_name][:,:,-1], mesh_x, mesh_y, num_zones, zone_depth)\n",
        "    \n",
        "\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    \n",
        "    if ts == pred_start or int(current_simulation_time*10000)%int(sinter_time*10000)==0:\n",
        "        # QGEN FEATURE\n",
        "        if single_qgen == True:\n",
        "            qgen_prediction_data = getAdjacentSinglePredict(qgen_full_maskset[:,:,ts+1], last_val_list_compare[0], mesh_x=60, mesh_y=118)\n",
        "        else:\n",
        "            qgen_prediction_data, nothing = getAdjacentFeaturesPredict(qgen_full_maskset[:,:,ts+1], last_val_list_compare[0],num_adjacent = num_adjacent,  udrl = udrl)\n",
        "\n",
        "        # QGEN DIST FEATURE\n",
        "        # get qgen dist feature in mesh form\n",
        "        qgen_dist_mat_compare = np.repeat(qgen_dist_dict_compare[mask][:, :, np.newaxis], temp_data_dict_compare[mask].shape[2], axis=2)\n",
        "        # get qgen dist data\n",
        "        if single_qgen_dist == True:\n",
        "            qgen_dist_prediction_data = getAdjacentSinglePredict(qgen_dist_full_maskset[:,:,ts+1], last_val_list_compare[0], mesh_x=60, mesh_y=118)\n",
        "        else:\n",
        "            qgen_dist_prediction_data, temp_mat_exp = getAdjacentFeaturesPredict(qgen_dist_full_maskset[:,:,ts+1], last_val_list_compare[0],num_adjacent = num_adjacent, udrl = udrl)\n",
        "\n",
        "        \n",
        "        qgen_zone_list_pred = getQgenZones(qgen_full_maskset[:,:,ts+1], mesh_x, mesh_y, num_zones, zone_depth, delay_jump = delay_jump, circle_zones = circle_zones ,zone_exp = zone_exp)\n",
        "\n",
        "\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "\n",
        "\n",
        "    # qgen_zone toggle\n",
        "    if qgen_zones == True:\n",
        "        pred_array = addQgenZonesPredict(pred_array, qgen_zone_list_pred, mesh_x, mesh_y, num_zones, zone_depth) # qgen_zone_list_pred\n",
        "    #print(pred_array.shape)\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(\"Time: \", end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuZ-_BG7UF2V"
      },
      "outputs": [],
      "source": [
        "#@title Plot Predicted vs Actual Temp Cross Section at Specified Timestep\n",
        "cs_ts = 131 #num_timesteps\n",
        "mask_name = pred_name\n",
        "y = predicted_temps[30,:,cs_ts]\n",
        "y = np.reshape(y, (-1,1))\n",
        "x = np.array([range(0, len(y)-1 + 1)]).transpose()\n",
        "\n",
        "y2 = temp_data_dict_compare[mask_name][30,:,cs_ts] \n",
        "y2 = np.reshape(y2, (-1,1))\n",
        "\n",
        "plt.plot(x, y, label = \"ML Predicted Temp\")\n",
        "plt.plot(x, y2, label = \"Actual Temp\")\n",
        "plt.legend()\n",
        "plt.title('ML Prediction vs Actual (Temperature Cross Sections)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcbZtNidUFJ4"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Plot Predicted vs Actual Temp of Individual Elements\n",
        "row = 30\n",
        "col = 59\n",
        "y = predicted_temps[row,col ,:]\n",
        "y = np.reshape(y, (-1,1))\n",
        "#x = np.array([range(0, num_time_pred+1)]).transpose()          xgb_res\n",
        "x = np.arange(0, 2, 2/(num_time_pred + 1)).transpose()\n",
        "x = np.reshape(x, (-1,1))\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n",
        "y2 = temp_data_dict_compare[mask_name][row,col ,:-1]\n",
        "y2 = np.reshape(y2, (-1,1))\n",
        "\n",
        "plt.plot(x, y, label = \"ANN Predicted Temp\")\n",
        "plt.plot(x, y2, label = \"FEA Calculated Temp\")\n",
        "plt.legend()\n",
        "plt.title('Temperature At Center Element (ML vs FEA)')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Temperature (°C)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-u4xTuL2yXi1"
      },
      "outputs": [],
      "source": [
        "#@title Plot NN Predicted Temp\n",
        "# create temperature plot\n",
        "import math\n",
        "\n",
        "'''\n",
        "\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "temp_plot_interval = 100/2\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "#temp_max = np.amax(temp_data_dict_compare[mask_name][:]) + 100 #+ 1*temp_plot_interval\n",
        "temp_max = 1200 #np.amax(predicted_temps[:])\n",
        "upper_temp = math.ceil(temp_max/temp_plot_interval)*temp_plot_interval\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "Z = predicted_temps[:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "Z = np.flip(Z,axis=0)\n",
        "fig,ax=plt.subplots(1,1)\n",
        "cp = ax.contourf(X, Y, Z, levels=list(np.arange(0,upper_temp+temp_plot_interval,temp_plot_interval)))\n",
        "fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('NN Predicted Temperatures at t=.015s (°C)')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "ax.set_xlabel('X Position (mm)')\n",
        "ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax.set_yticklabels(y_values.round(2))\n",
        "\n",
        "#fig.clim(0, 1000)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZZToIMA3czWQ"
      },
      "outputs": [],
      "source": [
        "#@title Plot FEA Predicted Temp\n",
        "# create temperature plot\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y\n",
        "\n",
        "'''\n",
        "\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "\n",
        "temp_plot_interval = 100/5*(5/3)\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "temp_max = np.amax(temp_data_dict_compare[mask_name][:]) #+ 100\n",
        "#temp_max = np.amax(temp_data_dict['yinyang'][:])\n",
        "upper_temp = math.ceil(temp_max/temp_plot_interval)*temp_plot_interval\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "Z = temp_data_dict_compare[mask_name][:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "Z = np.flip(Z,axis=0)\n",
        "#Z = temp_data_dict['yinyang'][:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "\n",
        "fig,ax=plt.subplots(1,1)\n",
        "cp = ax.contourf(X, Y, Z, levels=list(np.arange(0,upper_temp+temp_plot_interval,temp_plot_interval)))\n",
        "fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('FEA Temperatures (°C)')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "ax.set_xlabel('X Position (mm)')\n",
        "ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax.set_yticklabels(y_values.round(2))\n",
        "\n",
        "#fig.clim(0, 1000)\n",
        "plt.show()\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OoNF8_lTdU45"
      },
      "outputs": [],
      "source": [
        "#@title Plot Heat Generation\n",
        "# create temperature plot\n",
        "\n",
        "'''\n",
        "\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "Z = qgen_data_dict_compare[mask_name][:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "Z = np.flip(Z,axis=0)\n",
        "#Z = qgen_data_dict['smallsquare'][:,:,133]\n",
        "fig,ax=plt.subplots(1,1)\n",
        "\n",
        "\n",
        "#c_white = mpl.colors.colorConverter.to_rgba('white',alpha = 0)\n",
        "#c_black= mpl.colors.colorConverter.to_rgba('black',alpha = 1)\n",
        "#cmap = mpl.colors.LinearSegmentedColormap.from_list('rb_cmap',[c_white,c_black])\n",
        "\n",
        "\n",
        "cp = ax.contourf(X, Y, Z, levels=[0,0.5,1], cmap = mpl.colors.ListedColormap(['black', 'white']), interpolation='nearest')    #cmap = 'Greys_r', binary_r\n",
        "#fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('Normalized Qgen (Current Mask)')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "ax.set_xlabel('X Distance (mm)')\n",
        "ax.set_ylabel('Y Distance (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax.set_yticklabels(y_values.round(2))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7K7jDtBsyeny"
      },
      "outputs": [],
      "source": [
        "#@title Plot Qgen Zone Feature\n",
        "# create density plot\n",
        "\n",
        "'''\n",
        "\n",
        "if mesh_y<mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "xlist = np.linspace(0, mesh_y, mesh_y)\n",
        "ylist = np.linspace(0,mesh_x, mesh_x)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "#Z = qgen_mat_train[:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "Z = qgen_zone_list_dict['ibeam'][-2]  #np.sqrt(X**2 + Y**2)\n",
        "#Z = qgen_zone_list[2]\n",
        "fig,ax=plt.subplots(1,1)\n",
        "cp = ax.contourf(X, Y, Z)\n",
        "fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('Qgen Zone Features for Ibeam')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RtM-XfibI_RS"
      },
      "outputs": [],
      "source": [
        "#@title Plot Qgen Zone Feature for Prediction\n",
        "# create temperature plot\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "\n",
        "temp_plot_interval = 12.5*2\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "zone = 5\n",
        "\n",
        "temp_max = np.amax(qgen_zone_list_pred[zone - 1])\n",
        "#temp_max = np.amax(temp_data_dict['yinyang'][:])\n",
        "upper_temp = math.ceil(temp_max/temp_plot_interval)*temp_plot_interval\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "Z = qgen_zone_list_pred[zone - 1]  #np.sqrt(X**2 + Y**2)\n",
        "Z = np.flip(Z,axis=0)\n",
        "#Z = temp_data_dict['yinyang'][:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "\n",
        "fig,ax=plt.subplots(1,1)\n",
        "cp = ax.contourf(X, Y, Z, levels=list(np.arange(0,upper_temp+temp_plot_interval,temp_plot_interval)))\n",
        "fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('Qgen Zone Features: Prediction Mask')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "ax.set_xlabel('X Position (mm)')\n",
        "ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax.set_yticklabels(y_values.round(2))\n",
        "\n",
        "#fig.clim(0, 1000)\n",
        "plt.show()\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C85ov_VcMzc"
      },
      "outputs": [],
      "source": [
        "#@title #TEMPORARY NUM_TIMESTEP CHANGE\n",
        "print(num_timesteps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8DyLqq7UE71"
      },
      "outputs": [],
      "source": [
        "print(np.amax(predicted_temps[:,:,14]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DWr4JajScEb"
      },
      "outputs": [],
      "source": [
        "#@title Temperature Map Comparison Plot\n",
        "# create temperature plot\n",
        "import math\n",
        "\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "\n",
        "max_time_s = 2\n",
        "max_timestep = num_timesteps #133\n",
        "timestep = num_timesteps #133\n",
        "time_s = round(timestep*max_time_s/max_timestep,3)\n",
        "\n",
        "temp_plot_interval = 100/6\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "temp_max = np.amax(temp_data_dict_compare[mask_name][:]) +100 #+4*temp_plot_interval\n",
        "upper_temp = math.ceil(temp_max/temp_plot_interval)*temp_plot_interval\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "Z = predicted_temps[:,:,timestep]  #np.sqrt(X**2 + Y**2)\n",
        "Z = np.flip(Z,axis=0)\n",
        "fig,[ax,ax2]=plt.subplots(2,1)\n",
        "cp = ax.contourf(X, Y, Z, levels=list(np.arange(0,upper_temp+temp_plot_interval,temp_plot_interval)))\n",
        "#fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('NN Predicted Temperatures at t=' + str(time_s) + 's')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "ax.set_xlabel('X Position (mm)')\n",
        "ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax.set_yticklabels(y_values.round(2))\n",
        "\n",
        "\n",
        "\n",
        "Z2 = temp_data_dict_compare[mask_name][:,:,timestep]  #np.sqrt(X**2 + Y**2)\n",
        "Z2 = np.flip(Z2,axis=0)\n",
        "cp2 = ax2.contourf(X, Y, Z2, levels=list(np.arange(0,upper_temp+temp_plot_interval,temp_plot_interval)))\n",
        "#fig.colorbar(cp2) # Add a colorbar to a plot\n",
        "ax2.set_title('FEA Predicted Temperatures at t=' + str(time_s) + 's')\n",
        "ax2.set_aspect('equal')\n",
        "\n",
        "ax2.set_xlabel('X Distance (mm)')\n",
        "ax2.set_ylabel('Y Distance (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax2.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax2.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax2.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax2.set_yticklabels(y_values.round(2))\n",
        "\n",
        "\n",
        "#plot color bar\n",
        "fig.subplots_adjust(right=1.05)\n",
        "cbar_ax = fig.add_axes([0.80, 0.15, 0.025, 0.7])\n",
        "cbr = fig.colorbar(cp2, cax=cbar_ax)  # label = '°C' ... would want this above colorbar\n",
        "cbr.ax.set_title('°C')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3Z7_Go-tUwP"
      },
      "outputs": [],
      "source": [
        "#@title Density Map Comparison Plot\n",
        "# create temperature plot\n",
        "import math\n",
        "\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "max_time_s = 2\n",
        "max_timestep = num_timesteps #133\n",
        "timestep = num_timesteps #133\n",
        "time_s = round(timestep*max_time_s/max_timestep,3)\n",
        "\n",
        "dens_plot_interval = 100*2\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "lower_dens = 2600\n",
        "dens_max = np.amax(predicted_dens[:,:,timestep]) + 100 #+4*dens_plot_interval\n",
        "upper_dens = math.ceil(dens_max/dens_plot_interval)*dens_plot_interval\n",
        "print(upper_dens)\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "Z = predicted_dens[:,:,timestep]  #np.sqrt(X**2 + Y**2)\n",
        "Z = np.flip(Z,axis=0)\n",
        "fig,[ax,ax2]=plt.subplots(2,1)\n",
        "cp = ax.contourf(X, Y, Z, levels=list(np.arange(lower_dens,upper_dens+dens_plot_interval,dens_plot_interval)))\n",
        "#fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('NN Predicted Density at t=' + str(time_s) + 's')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "ax.set_xlabel('X Position (mm)')\n",
        "ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax.set_yticklabels(y_values.round(2))\n",
        "\n",
        "\n",
        "\n",
        "Z2 = dens_data_dict_compare[mask_name][:,:,timestep]  #np.sqrt(X**2 + Y**2)\n",
        "Z2 = np.flip(Z2,axis=0)\n",
        "cp2 = ax2.contourf(X, Y, Z2, levels=list(np.arange(lower_dens,upper_dens+dens_plot_interval,dens_plot_interval)))\n",
        "#fig.colorbar(cp2) # Add a colorbar to a plot\n",
        "ax2.set_title('FEA Predicted Density at t=' + str(time_s) + 's')\n",
        "ax2.set_aspect('equal')\n",
        "\n",
        "ax2.set_xlabel('X Distance (mm)')\n",
        "ax2.set_ylabel('Y Distance (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax2.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax2.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax2.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax2.set_yticklabels(y_values.round(2))\n",
        "\n",
        "\n",
        "#plot color bar\n",
        "fig.subplots_adjust(right=1.05)\n",
        "cbar_ax = fig.add_axes([0.80, 0.15, 0.025, 0.7])\n",
        "cbr = fig.colorbar(cp2, cax=cbar_ax)  # label = '°C' ... would want this above colorbar\n",
        "cbr.ax.set_title('kg/m^3')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV-4a1aN-p6l"
      },
      "outputs": [],
      "source": [
        "#@title Density Comparison\n",
        "x = np.arange(1,predicted_dens.shape[2])\n",
        "y = np.array([np.amax(predicted_dens[:,:,num]) for num in x]) #dens_data_dict_compare[mask_name]\n",
        "y2 = np.array([np.amax(dens_data_dict_compare[mask_name][:,:,num]) for num in x])\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnaWMpG0SLWp"
      },
      "outputs": [],
      "source": [
        "#@title Temperature Error Plot\n",
        "\n",
        "# create temperature plot\n",
        "import math\n",
        "\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "ts = num_timesteps #133\n",
        "\n",
        "temp_plot_interval = 10\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "error_mat = predicted_temps - temp_data_dict_compare[mask_name][:,:,:-1]\n",
        "Z = error_mat[:,:,ts]\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "#Z = predicted_temps[:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "Z = np.flip(Z,axis=0)\n",
        "fig,ax=plt.subplots(1,1)\n",
        "cp = ax.contourf(X, Y, Z)\n",
        "fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('Temperature Error (°C)')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "ax.set_xlabel('X Position (mm)')\n",
        "ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax.set_yticklabels(y_values.round(2))\n",
        "\n",
        "#fig.clim(0, 1000)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUHMJgOSUDb6"
      },
      "outputs": [],
      "source": [
        "#@title Absolute Temperature Error Plot\n",
        "\n",
        "# create temperature plot\n",
        "import math\n",
        "\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "ts = num_timesteps #125 #133\n",
        "\n",
        "temp_plot_interval = 10/2\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "error_mat_abs = abs(temp_data_dict_compare[mask_name][:,:,:-1] - predicted_temps)\n",
        "Z = error_mat_abs[:,:,ts]\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "#Z = predicted_temps[:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "Z = np.flip(Z,axis=0)\n",
        "fig,ax=plt.subplots(1,1)\n",
        "cp = ax.contourf(X, Y, Z)\n",
        "fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('Absolute Temperature Error (°C)')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "ax.set_xlabel('X Position (mm)')\n",
        "ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax.set_yticklabels(y_values.round(2))\n",
        "\n",
        "#fig.clim(0, 1000)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZqSZY9gUQEh"
      },
      "outputs": [],
      "source": [
        "ts = ts\n",
        "print(\"Mean Absolute Error: \" + str(np.average(error_mat_abs[:,:,ts])))\n",
        "print(\"Max Absolute Error: \" + str(np.amax(error_mat_abs[:,:,ts])))\n",
        "print(\"Min Absolute Error: \" + str(np.amin(error_mat_abs[:,:,ts])))\n",
        "\n",
        "max_temp = np.amax(temp_data_dict_compare[mask_name][:,:,ts])\n",
        "error_mat_perc = error_mat_abs[:,:,ts]/temp_data_dict_compare[mask_name][:,:,ts]*100\n",
        "print(\"Max Temp: \" + str(max_temp))\n",
        "print(\"Average Temperature: \" + str(np.average(temp_data_dict_compare[mask_name][:,:,ts])))\n",
        "print(\"Average Percent Error: \" + str(np.average(error_mat_perc[:,:])))\n",
        "print(\"Max Percent Error: \" + str(np.amax(error_mat_perc[:])))\n",
        "print(ts) # circle5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsja2tC9XNWj"
      },
      "outputs": [],
      "source": [
        "#@title Average Temperature Error vs Number of Predictions \n",
        "x = np.arange(1,predicted_dens.shape[2])\n",
        "y = np.array([np.amax(np.average(error_mat_abs[:,:,num])) for num in x]) #dens_data_dict_compare[mask_name]\n",
        "plt.plot(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwccfyTPYe69"
      },
      "outputs": [],
      "source": [
        "#@title Temperature Percentage Error Plot\n",
        "\n",
        "# create temperature plot\n",
        "import math\n",
        "\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "temp_plot_interval = 10/2\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "Z = error_mat_perc\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "#Z = predicted_temps[:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "Z = np.flip(Z,axis=0)\n",
        "fig,ax=plt.subplots(1,1)\n",
        "cp = ax.contourf(X, Y, Z, levels=list(np.arange(0,80+10,temp_plot_interval)))\n",
        "fig.colorbar(cp) # Add a colorbar to a plot\n",
        "ax.set_title('Temperature Percentage Error (%)')\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "ax.set_xlabel('X Position (mm)')\n",
        "ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "ax.set_xticks(x_tick_locs)\n",
        "x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "ax.set_yticks(y_tick_locs)\n",
        "y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "ax.set_yticklabels(y_values.round(2))\n",
        "\n",
        "#fig.clim(0, 1000)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX0AdyuJ42F5"
      },
      "outputs": [],
      "source": [
        "#@title Plot Predicted Temp (Video)\n",
        "\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "\n",
        "temp_plot_interval = 100/2\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "temp_max = np.amax(predicted_temps[:]) + 50\n",
        "#temp_max = np.amax(temp_data_dict['yinyang'][:])\n",
        "upper_temp = math.ceil(temp_max/temp_plot_interval)*temp_plot_interval\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "#Z = temp_data_dict_compare[mask_name][:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "#Z = np.flip(Z,axis=0)\n",
        "#Z = temp_data_dict['yinyang'][:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "\n",
        "fig,ax=plt.subplots(1,1)\n",
        "\n",
        "cp = ax.contourf(X, Y, Z, levels=list(np.arange(0,upper_temp+temp_plot_interval,temp_plot_interval)))\n",
        "#fig.colorbar(cp) # Add a colorbar to a plot\n",
        "\n",
        "def animate(i):\n",
        "        \n",
        "    #Z = temp_data_dict_compare[mask_name][:,:,i]  #np.sqrt(X**2 + Y**2)\n",
        "    Z = predicted_temps[:,:,i]\n",
        "    Z = np.flip(Z,axis=0)\n",
        "\n",
        "    ax.contourf(X, Y, Z, levels=list(np.arange(0,upper_temp+temp_plot_interval,temp_plot_interval)))\n",
        "\n",
        "    \n",
        "    ax.set_title('NN Predicted Temperatures (°C)')\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "    ax.set_xlabel('X Position (mm)')\n",
        "    ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "    x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "    ax.set_xticks(x_tick_locs)\n",
        "    x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "    ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "    y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "    ax.set_yticks(y_tick_locs)\n",
        "    y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "    ax.set_yticklabels(y_values.round(2))\n",
        "    \n",
        "\n",
        "# Call animate method\n",
        "ani = animation.FuncAnimation(fig, animate, num_timesteps, interval=50, blit=False)\n",
        "\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "ani\n",
        "\n",
        "# Display the plot\n",
        "#plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgvuYt83gGJo"
      },
      "outputs": [],
      "source": [
        "#@title Plot Predicted Temp (Video)\n",
        "\n",
        "# FOR PLOTTING: FLIP mesh_x and mesh_y\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "if mesh_y>mesh_x:\n",
        "    mesh_x, mesh_y = mesh_y, mesh_x\n",
        "\n",
        "\n",
        "temp_plot_interval = 100\n",
        "x_plot_interval = 5\n",
        "y_plot_interval = 5\n",
        "y_max = 1.5\n",
        "x_max = 3\n",
        "\n",
        "temp_max = np.amax(temp_data_dict_compare[mask_name][:]) + 100\n",
        "#temp_max = np.amax(temp_data_dict['yinyang'][:])\n",
        "upper_temp = math.ceil(temp_max/temp_plot_interval)*temp_plot_interval\n",
        "\n",
        "xlist = np.linspace(0, mesh_x, mesh_x)\n",
        "ylist = np.linspace(0,mesh_y, mesh_y)\n",
        "X, Y = np.meshgrid(xlist, ylist)\n",
        "#Z = temp_data_dict_compare[mask_name][:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "#Z = np.flip(Z,axis=0)\n",
        "#Z = temp_data_dict['yinyang'][:,:,133]  #np.sqrt(X**2 + Y**2)\n",
        "\n",
        "fig,ax=plt.subplots(1,1)\n",
        "cp = ax.contourf(X, Y, Z, levels=list(np.arange(0,upper_temp+temp_plot_interval,temp_plot_interval)))\n",
        "#fig.colorbar(cp) # Add a colorbar to a plot\n",
        "\n",
        "def animate(i):\n",
        "        \n",
        "    Z = temp_data_dict_compare[mask_name][:,:,i]  #np.sqrt(X**2 + Y**2)\n",
        "    #Z = predicted_temps[:,:,i]\n",
        "    Z = np.flip(Z,axis=0)\n",
        "\n",
        "    ax.contourf(X, Y, Z, levels=list(np.arange(0,upper_temp+temp_plot_interval,temp_plot_interval)))\n",
        "\n",
        "    \n",
        "    ax.set_title('FEA Predicted Temperatures (°C)')\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "    ax.set_xlabel('X Position (mm)')\n",
        "    ax.set_ylabel('Y Position (mm)')\n",
        "\n",
        "    x_tick_locs = np.arange(0, mesh_x+mesh_x/x_plot_interval, mesh_x/x_plot_interval)\n",
        "    ax.set_xticks(x_tick_locs)\n",
        "    x_values = np.arange(0, x_max+x_max/x_plot_interval, x_max/x_plot_interval)\n",
        "    ax.set_xticklabels(x_values.round(2))\n",
        "\n",
        "    y_tick_locs = np.arange(0, mesh_y + mesh_y/y_plot_interval, mesh_y/y_plot_interval)\n",
        "    ax.set_yticks(y_tick_locs)\n",
        "    y_values = np.arange(0, y_max + y_max/y_plot_interval, y_max/y_plot_interval)\n",
        "    ax.set_yticklabels(y_values.round(2))\n",
        "    \n",
        "\n",
        "# Call animate method\n",
        "ani = animation.FuncAnimation(fig, animate, num_timesteps, interval=50, blit=False)\n",
        "\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "ani\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}